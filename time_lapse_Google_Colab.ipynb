{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sparshsing/ai_timelapse/blob/main/time_lapse_Google_Colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "61-YrGoj3k2i"
      },
      "source": [
        "## Generate smooth Time lapse from multiple sequencial images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_kgDDtTe46tC",
        "outputId": "c6769ff2-95c1-45dd-adf3-8d0227d21c52"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'ai_timelapse'...\n",
            "remote: Enumerating objects: 85, done.\u001b[K\n",
            "remote: Counting objects: 100% (85/85), done.\u001b[K\n",
            "remote: Compressing objects: 100% (72/72), done.\u001b[K\n",
            "remote: Total 85 (delta 18), reused 78 (delta 13), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (85/85), 14.16 MiB | 9.08 MiB/s, done.\n",
            "Resolving deltas: 100% (18/18), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/Sparshsing/ai_timelapse.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kREPNgXA5tnY",
        "outputId": "8ff31145-618d-4541-b443-12d266cd0456"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/ai_timelapse\n"
          ]
        }
      ],
      "source": [
        "# change directory to ai_timelapse\n",
        "%cd ai_timelapse"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "lpfHWX8L5EL1",
        "outputId": "2d75c734-07d9-44d0-c427-4c5ca7fb2672"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/ai_timelapse'"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import os\n",
        "os.getcwd()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ksc3jxlD5guf",
        "outputId": "907805d2-55af-43f1-f1d8-f77ca31fa006"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fri Jan 17 06:22:03 2025       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   37C    P8               9W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "# check GPU (select T4 runtime in settings if error)\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "18PAgYHM7cW6",
        "outputId": "a9c300ca-0b2b-4b7b-b18f-be4e0eb4bc45"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 3)) (4.9.7)\n",
            "Collecting tensorflow-addons (from -r requirements.txt (line 4))\n",
            "  Downloading tensorflow_addons-0.23.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 5)) (1.4.0)\n",
            "Requirement already satisfied: gin-config in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 6)) (0.5.0)\n",
            "Collecting parameterized (from -r requirements.txt (line 7))\n",
            "  Downloading parameterized-0.9.0-py2.py3-none-any.whl.metadata (18 kB)\n",
            "Collecting mediapy (from -r requirements.txt (line 8))\n",
            "  Downloading mediapy-1.2.2-py3-none-any.whl.metadata (4.8 kB)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 9)) (0.25.0)\n",
            "Collecting apache-beam (from -r requirements.txt (line 10))\n",
            "  Downloading apache_beam-2.61.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.4 kB)\n",
            "Requirement already satisfied: google-cloud-bigquery-storage in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 11)) (2.27.0)\n",
            "Requirement already satisfied: natsort in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 12)) (8.4.0)\n",
            "Requirement already satisfied: gdown in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 13)) (5.2.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 14)) (4.67.1)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 15)) (4.10.0.84)\n",
            "Collecting mediapipe (from -r requirements.txt (line 16))\n",
            "  Downloading mediapipe-0.10.20-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (9.7 kB)\n",
            "Collecting rembg (from -r requirements.txt (line 17))\n",
            "  Downloading rembg-2.0.61-py3-none-any.whl.metadata (18 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 18)) (1.26.4)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from tensorflow-datasets->-r requirements.txt (line 3)) (8.1.8)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.11/dist-packages (from tensorflow-datasets->-r requirements.txt (line 3)) (0.1.8)\n",
            "Requirement already satisfied: immutabledict in /usr/local/lib/python3.11/dist-packages (from tensorflow-datasets->-r requirements.txt (line 3)) (4.2.1)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.11/dist-packages (from tensorflow-datasets->-r requirements.txt (line 3)) (2.3)\n",
            "Requirement already satisfied: protobuf>=3.20 in /usr/local/lib/python3.11/dist-packages (from tensorflow-datasets->-r requirements.txt (line 3)) (4.25.5)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from tensorflow-datasets->-r requirements.txt (line 3)) (5.9.5)\n",
            "Requirement already satisfied: pyarrow in /usr/local/lib/python3.11/dist-packages (from tensorflow-datasets->-r requirements.txt (line 3)) (17.0.0)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow-datasets->-r requirements.txt (line 3)) (2.32.3)\n",
            "Requirement already satisfied: simple-parsing in /usr/local/lib/python3.11/dist-packages (from tensorflow-datasets->-r requirements.txt (line 3)) (0.1.6)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.11/dist-packages (from tensorflow-datasets->-r requirements.txt (line 3)) (1.16.1)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.11/dist-packages (from tensorflow-datasets->-r requirements.txt (line 3)) (2.5.0)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.11/dist-packages (from tensorflow-datasets->-r requirements.txt (line 3)) (0.10.2)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from tensorflow-datasets->-r requirements.txt (line 3)) (1.17.0)\n",
            "Requirement already satisfied: array-record>=0.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow-datasets->-r requirements.txt (line 3)) (0.6.0)\n",
            "Requirement already satisfied: etils>=1.9.1 in /usr/local/lib/python3.11/dist-packages (from etils[edc,enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow-datasets->-r requirements.txt (line 3)) (1.11.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow-addons->-r requirements.txt (line 4)) (24.2)\n",
            "Collecting typeguard<3.0.0,>=2.7 (from tensorflow-addons->-r requirements.txt (line 4))\n",
            "  Downloading typeguard-2.13.3-py3-none-any.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.11/dist-packages (from mediapy->-r requirements.txt (line 8)) (7.34.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from mediapy->-r requirements.txt (line 8)) (3.10.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from mediapy->-r requirements.txt (line 8)) (11.1.0)\n",
            "Requirement already satisfied: scipy>=1.11.2 in /usr/local/lib/python3.11/dist-packages (from scikit-image->-r requirements.txt (line 9)) (1.13.1)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.11/dist-packages (from scikit-image->-r requirements.txt (line 9)) (3.4.2)\n",
            "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.11/dist-packages (from scikit-image->-r requirements.txt (line 9)) (2.36.1)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.11/dist-packages (from scikit-image->-r requirements.txt (line 9)) (2024.12.12)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image->-r requirements.txt (line 9)) (0.4)\n",
            "Collecting crcmod<2.0,>=1.7 (from apache-beam->-r requirements.txt (line 10))\n",
            "  Downloading crcmod-1.7.tar.gz (89 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.7/89.7 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: orjson<4,>=3.9.7 in /usr/local/lib/python3.11/dist-packages (from apache-beam->-r requirements.txt (line 10)) (3.10.14)\n",
            "Collecting dill<0.3.2,>=0.3.1.1 (from apache-beam->-r requirements.txt (line 10))\n",
            "  Downloading dill-0.3.1.1.tar.gz (151 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m152.0/152.0 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting cloudpickle~=2.2.1 (from apache-beam->-r requirements.txt (line 10))\n",
            "  Downloading cloudpickle-2.2.1-py3-none-any.whl.metadata (6.9 kB)\n",
            "Collecting fastavro<2,>=0.23.6 (from apache-beam->-r requirements.txt (line 10))\n",
            "  Downloading fastavro-1.10.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.5 kB)\n",
            "Collecting fasteners<1.0,>=0.3 (from apache-beam->-r requirements.txt (line 10))\n",
            "  Downloading fasteners-0.19-py3-none-any.whl.metadata (4.9 kB)\n",
            "Collecting grpcio!=1.48.0,!=1.59.*,!=1.60.*,!=1.61.*,!=1.62.0,!=1.62.1,<1.66.0,<2,>=1.33.1 (from apache-beam->-r requirements.txt (line 10))\n",
            "  Downloading grpcio-1.65.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.3 kB)\n",
            "Collecting hdfs<3.0.0,>=2.1.0 (from apache-beam->-r requirements.txt (line 10))\n",
            "  Downloading hdfs-2.7.3.tar.gz (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.5/43.5 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: httplib2<0.23.0,>=0.8 in /usr/local/lib/python3.11/dist-packages (from apache-beam->-r requirements.txt (line 10)) (0.22.0)\n",
            "Requirement already satisfied: jsonschema<5.0.0,>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from apache-beam->-r requirements.txt (line 10)) (4.23.0)\n",
            "Collecting jsonpickle<4.0.0,>=3.0.0 (from apache-beam->-r requirements.txt (line 10))\n",
            "  Downloading jsonpickle-3.4.2-py3-none-any.whl.metadata (8.1 kB)\n",
            "Collecting objsize<0.8.0,>=0.6.1 (from apache-beam->-r requirements.txt (line 10))\n",
            "  Downloading objsize-0.7.0-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting pymongo<5.0.0,>=3.8.0 (from apache-beam->-r requirements.txt (line 10))\n",
            "  Downloading pymongo-4.10.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (22 kB)\n",
            "Requirement already satisfied: proto-plus<2,>=1.7.1 in /usr/local/lib/python3.11/dist-packages (from apache-beam->-r requirements.txt (line 10)) (1.25.0)\n",
            "Collecting pydot<2,>=1.2.0 (from apache-beam->-r requirements.txt (line 10))\n",
            "  Downloading pydot-1.4.2-py2.py3-none-any.whl.metadata (8.0 kB)\n",
            "Requirement already satisfied: python-dateutil<3,>=2.8.0 in /usr/local/lib/python3.11/dist-packages (from apache-beam->-r requirements.txt (line 10)) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2018.3 in /usr/local/lib/python3.11/dist-packages (from apache-beam->-r requirements.txt (line 10)) (2024.2)\n",
            "Collecting redis<6,>=5.0.0 (from apache-beam->-r requirements.txt (line 10))\n",
            "  Downloading redis-5.2.1-py3-none-any.whl.metadata (9.1 kB)\n",
            "Requirement already satisfied: regex>=2020.6.8 in /usr/local/lib/python3.11/dist-packages (from apache-beam->-r requirements.txt (line 10)) (2024.11.6)\n",
            "Collecting sortedcontainers>=2.4.0 (from apache-beam->-r requirements.txt (line 10))\n",
            "  Downloading sortedcontainers-2.4.0-py2.py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: typing-extensions>=3.7.0 in /usr/local/lib/python3.11/dist-packages (from apache-beam->-r requirements.txt (line 10)) (4.12.2)\n",
            "Collecting zstandard<1,>=0.18.0 (from apache-beam->-r requirements.txt (line 10))\n",
            "  Downloading zstandard-0.23.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: pyyaml<7.0.0,>=3.12 in /usr/local/lib/python3.11/dist-packages (from apache-beam->-r requirements.txt (line 10)) (6.0.2)\n",
            "Collecting pyarrow (from tensorflow-datasets->-r requirements.txt (line 3))\n",
            "  Downloading pyarrow-16.1.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (3.0 kB)\n",
            "Collecting pyarrow-hotfix<1 (from apache-beam->-r requirements.txt (line 10))\n",
            "  Downloading pyarrow_hotfix-0.6-py3-none-any.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-bigquery-storage->-r requirements.txt (line 11)) (2.19.2)\n",
            "Requirement already satisfied: google-auth<3.0.0dev,>=2.14.1 in /usr/local/lib/python3.11/dist-packages (from google-cloud-bigquery-storage->-r requirements.txt (line 11)) (2.27.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from gdown->-r requirements.txt (line 13)) (4.12.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from gdown->-r requirements.txt (line 13)) (3.16.1)\n",
            "Requirement already satisfied: attrs>=19.1.0 in /usr/local/lib/python3.11/dist-packages (from mediapipe->-r requirements.txt (line 16)) (24.3.0)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.11/dist-packages (from mediapipe->-r requirements.txt (line 16)) (24.12.23)\n",
            "Requirement already satisfied: jax in /usr/local/lib/python3.11/dist-packages (from mediapipe->-r requirements.txt (line 16)) (0.4.33)\n",
            "Requirement already satisfied: jaxlib in /usr/local/lib/python3.11/dist-packages (from mediapipe->-r requirements.txt (line 16)) (0.4.33)\n",
            "Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.11/dist-packages (from mediapipe->-r requirements.txt (line 16)) (4.10.0.84)\n",
            "Collecting sounddevice>=0.4.4 (from mediapipe->-r requirements.txt (line 16))\n",
            "  Downloading sounddevice-0.5.1-py3-none-any.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (from mediapipe->-r requirements.txt (line 16)) (0.2.0)\n",
            "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.11/dist-packages (from rembg->-r requirements.txt (line 17)) (4.10.0.84)\n",
            "Requirement already satisfied: pooch in /usr/local/lib/python3.11/dist-packages (from rembg->-r requirements.txt (line 17)) (1.8.2)\n",
            "Collecting pymatting (from rembg->-r requirements.txt (line 17))\n",
            "  Downloading PyMatting-1.1.13-py3-none-any.whl.metadata (7.5 kB)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from etils[edc,enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow-datasets->-r requirements.txt (line 3)) (2024.10.0)\n",
            "Requirement already satisfied: importlib_resources in /usr/local/lib/python3.11/dist-packages (from etils[edc,enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow-datasets->-r requirements.txt (line 3)) (6.5.2)\n",
            "Requirement already satisfied: zipp in /usr/local/lib/python3.11/dist-packages (from etils[edc,enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow-datasets->-r requirements.txt (line 3)) (3.21.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-bigquery-storage->-r requirements.txt (line 11)) (1.66.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-bigquery-storage->-r requirements.txt (line 11)) (1.62.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-bigquery-storage->-r requirements.txt (line 11)) (5.5.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-bigquery-storage->-r requirements.txt (line 11)) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-bigquery-storage->-r requirements.txt (line 11)) (4.9)\n",
            "Collecting docopt (from hdfs<3.0.0,>=2.1.0->apache-beam->-r requirements.txt (line 10))\n",
            "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from hdfs<3.0.0,>=2.1.0->apache-beam->-r requirements.txt (line 10)) (1.17.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.11/dist-packages (from httplib2<0.23.0,>=0.8->apache-beam->-r requirements.txt (line 10)) (3.2.1)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema<5.0.0,>=4.0.0->apache-beam->-r requirements.txt (line 10)) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema<5.0.0,>=4.0.0->apache-beam->-r requirements.txt (line 10)) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema<5.0.0,>=4.0.0->apache-beam->-r requirements.txt (line 10)) (0.22.3)\n",
            "Collecting dnspython<3.0.0,>=1.16.0 (from pymongo<5.0.0,>=3.8.0->apache-beam->-r requirements.txt (line 10))\n",
            "  Downloading dnspython-2.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->tensorflow-datasets->-r requirements.txt (line 3)) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->tensorflow-datasets->-r requirements.txt (line 3)) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->tensorflow-datasets->-r requirements.txt (line 3)) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->tensorflow-datasets->-r requirements.txt (line 3)) (2024.12.14)\n",
            "Requirement already satisfied: CFFI>=1.0 in /usr/local/lib/python3.11/dist-packages (from sounddevice>=0.4.4->mediapipe->-r requirements.txt (line 16)) (1.17.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->gdown->-r requirements.txt (line 13)) (2.6)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.11/dist-packages (from ipython->mediapy->-r requirements.txt (line 8)) (75.1.0)\n",
            "Collecting jedi>=0.16 (from ipython->mediapy->-r requirements.txt (line 8))\n",
            "  Downloading jedi-0.19.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from ipython->mediapy->-r requirements.txt (line 8)) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.11/dist-packages (from ipython->mediapy->-r requirements.txt (line 8)) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.11/dist-packages (from ipython->mediapy->-r requirements.txt (line 8)) (5.7.1)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ipython->mediapy->-r requirements.txt (line 8)) (3.0.48)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.11/dist-packages (from ipython->mediapy->-r requirements.txt (line 8)) (2.18.0)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.11/dist-packages (from ipython->mediapy->-r requirements.txt (line 8)) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.11/dist-packages (from ipython->mediapy->-r requirements.txt (line 8)) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.11/dist-packages (from ipython->mediapy->-r requirements.txt (line 8)) (4.9.0)\n",
            "Requirement already satisfied: ml-dtypes>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from jax->mediapipe->-r requirements.txt (line 16)) (0.4.1)\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.11/dist-packages (from jax->mediapipe->-r requirements.txt (line 16)) (3.4.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapy->-r requirements.txt (line 8)) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapy->-r requirements.txt (line 8)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapy->-r requirements.txt (line 8)) (4.55.3)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapy->-r requirements.txt (line 8)) (1.4.8)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from pooch->rembg->-r requirements.txt (line 17)) (4.3.6)\n",
            "Requirement already satisfied: numba!=0.49.0 in /usr/local/lib/python3.11/dist-packages (from pymatting->rembg->-r requirements.txt (line 17)) (0.60.0)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown->-r requirements.txt (line 13)) (1.7.1)\n",
            "Requirement already satisfied: docstring-parser<1.0,>=0.15 in /usr/local/lib/python3.11/dist-packages (from simple-parsing->tensorflow-datasets->-r requirements.txt (line 3)) (0.16)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe->-r requirements.txt (line 16)) (2.22)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.11/dist-packages (from jedi>=0.16->ipython->mediapy->-r requirements.txt (line 8)) (0.8.4)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba!=0.49.0->pymatting->rembg->-r requirements.txt (line 17)) (0.43.0)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.11/dist-packages (from pexpect>4.3->ipython->mediapy->-r requirements.txt (line 8)) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython->mediapy->-r requirements.txt (line 8)) (0.2.13)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0dev,>=2.14.1->google-cloud-bigquery-storage->-r requirements.txt (line 11)) (0.6.1)\n",
            "Downloading tensorflow_addons-0.23.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (611 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m611.8/611.8 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading parameterized-0.9.0-py2.py3-none-any.whl (20 kB)\n",
            "Downloading mediapy-1.2.2-py3-none-any.whl (26 kB)\n",
            "Downloading apache_beam-2.61.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.9/16.9 MB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mediapipe-0.10.20-cp311-cp311-manylinux_2_28_x86_64.whl (35.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m35.6/35.6 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rembg-2.0.61-py3-none-any.whl (40 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.5/40.5 kB\u001b[0m \u001b[31m700.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cloudpickle-2.2.1-py3-none-any.whl (25 kB)\n",
            "Downloading fastavro-1.10.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fasteners-0.19-py3-none-any.whl (18 kB)\n",
            "Downloading grpcio-1.65.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.7/5.7 MB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jsonpickle-3.4.2-py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.3/46.3 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading objsize-0.7.0-py3-none-any.whl (11 kB)\n",
            "Downloading pyarrow-16.1.0-cp311-cp311-manylinux_2_28_x86_64.whl (40.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.8/40.8 MB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyarrow_hotfix-0.6-py3-none-any.whl (7.9 kB)\n",
            "Downloading pydot-1.4.2-py2.py3-none-any.whl (21 kB)\n",
            "Downloading pymongo-4.10.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading redis-5.2.1-py3-none-any.whl (261 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m261.5/261.5 kB\u001b[0m \u001b[31m26.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sortedcontainers-2.4.0-py2.py3-none-any.whl (29 kB)\n",
            "Downloading sounddevice-0.5.1-py3-none-any.whl (32 kB)\n",
            "Downloading typeguard-2.13.3-py3-none-any.whl (17 kB)\n",
            "Downloading zstandard-0.23.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading PyMatting-1.1.13-py3-none-any.whl (54 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dnspython-2.7.0-py3-none-any.whl (313 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m313.6/313.6 kB\u001b[0m \u001b[31m28.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jedi-0.19.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m29.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: crcmod, dill, hdfs, docopt\n",
            "  Building wheel for crcmod (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for crcmod: filename=crcmod-1.7-cp311-cp311-linux_x86_64.whl size=31656 sha256=d506eb5bd7af5e698da3d9ea3d6ad124505982e198e41e0b01c6183a81b1cb0d\n",
            "  Stored in directory: /root/.cache/pip/wheels/23/94/7a/8cb7d14597e6395ce969933f01aed9ea8fa5f5b4d4c8a61e99\n",
            "  Building wheel for dill (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for dill: filename=dill-0.3.1.1-py3-none-any.whl size=78542 sha256=5b375ae641f50251a0b5a87aaa351941ee2ed2a2f82ca43648c0675f630a5146\n",
            "  Stored in directory: /root/.cache/pip/wheels/01/60/80/1622338bcecce31a5664ef01c203cc5a7b09f59588d9c07376\n",
            "  Building wheel for hdfs (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for hdfs: filename=hdfs-2.7.3-py3-none-any.whl size=34324 sha256=994a44fbfa6c76124387e305a6f6de9e0658f028cccb41c0d6aedc2b35e50a5f\n",
            "  Stored in directory: /root/.cache/pip/wheels/b9/1d/dc/eb0833be25464c359903d356c4204721c6a672c26ff164cdc3\n",
            "  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13706 sha256=2faca7b7a1c2f4b758a290416b8bd671a175a8cc4debf0b315681e2fa56f7d0a\n",
            "  Stored in directory: /root/.cache/pip/wheels/1a/b0/8c/4b75c4116c31f83c8f9f047231251e13cc74481cca4a78a9ce\n",
            "Successfully built crcmod dill hdfs docopt\n",
            "Installing collected packages: sortedcontainers, docopt, crcmod, zstandard, typeguard, redis, pydot, pyarrow-hotfix, pyarrow, parameterized, objsize, jsonpickle, jedi, grpcio, fasteners, fastavro, dnspython, dill, cloudpickle, tensorflow-addons, sounddevice, pymongo, pymatting, hdfs, mediapy, rembg, mediapipe, apache-beam\n",
            "  Attempting uninstall: typeguard\n",
            "    Found existing installation: typeguard 4.4.1\n",
            "    Uninstalling typeguard-4.4.1:\n",
            "      Successfully uninstalled typeguard-4.4.1\n",
            "  Attempting uninstall: pydot\n",
            "    Found existing installation: pydot 3.0.4\n",
            "    Uninstalling pydot-3.0.4:\n",
            "      Successfully uninstalled pydot-3.0.4\n",
            "  Attempting uninstall: pyarrow\n",
            "    Found existing installation: pyarrow 17.0.0\n",
            "    Uninstalling pyarrow-17.0.0:\n",
            "      Successfully uninstalled pyarrow-17.0.0\n",
            "  Attempting uninstall: jsonpickle\n",
            "    Found existing installation: jsonpickle 4.0.1\n",
            "    Uninstalling jsonpickle-4.0.1:\n",
            "      Successfully uninstalled jsonpickle-4.0.1\n",
            "  Attempting uninstall: grpcio\n",
            "    Found existing installation: grpcio 1.69.0\n",
            "    Uninstalling grpcio-1.69.0:\n",
            "      Successfully uninstalled grpcio-1.69.0\n",
            "  Attempting uninstall: cloudpickle\n",
            "    Found existing installation: cloudpickle 3.1.0\n",
            "    Uninstalling cloudpickle-3.1.0:\n",
            "      Successfully uninstalled cloudpickle-3.1.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "inflect 7.5.0 requires typeguard>=4.0.1, but you have typeguard 2.13.3 which is incompatible.\n",
            "dask 2024.10.0 requires cloudpickle>=3.0.0, but you have cloudpickle 2.2.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed apache-beam-2.61.0 cloudpickle-2.2.1 crcmod-1.7 dill-0.3.1.1 dnspython-2.7.0 docopt-0.6.2 fastavro-1.10.0 fasteners-0.19 grpcio-1.65.5 hdfs-2.7.3 jedi-0.19.2 jsonpickle-3.4.2 mediapipe-0.10.20 mediapy-1.2.2 objsize-0.7.0 parameterized-0.9.0 pyarrow-16.1.0 pyarrow-hotfix-0.6 pydot-1.4.2 pymatting-1.1.13 pymongo-4.10.1 redis-5.2.1 rembg-2.0.61 sortedcontainers-2.4.0 sounddevice-0.5.1 tensorflow-addons-0.23.0 typeguard-2.13.3 zstandard-0.23.0\n"
          ]
        }
      ],
      "source": [
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Settings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "vdgoCPVo3k2k"
      },
      "outputs": [],
      "source": [
        "INPUT_DIR = 'input_frames/shahrukh-khan'\n",
        "OUTPUT_DIR = 'output_frames/shahrukh-khan'\n",
        "REFERENCE_IMG_NAME = '2017_raees.jpg'  # reference image for face tilt and lighting\n",
        "\n",
        "preprocess_faces = True\n",
        "FIX_LIGHTING = False  # to make images have a similar color\n",
        "equal_intervals = True  # whether to use equal no of frames between images or decide based on date\n",
        "\n",
        "# applicable when equal_intervals is False\n",
        "# desired gap between frames in seconds (difference between dates of frames)\n",
        "# eg. set 3600 to generate 1 frame for every 1 hr gap in input images\n",
        "min_frame_duration = 3600 * 24"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "nwB5mYvR3k2k"
      },
      "outputs": [],
      "source": [
        "\n",
        "MAX_DIM = 1080\n",
        "# set no of interpolated frames between images\n",
        "MAX_INTERPOLATED_FRAMES = 15  # 1 less than powers of 2\n",
        "MODEL_PATH = \"pretrained_models/film_net/Style/saved_model\"\n",
        "VALID_IMG_FORMATS = ('.png', '.jpg', '.jpeg', '.bmp')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "uVxhyExg3k2k"
      },
      "outputs": [],
      "source": [
        "if MAX_INTERPOLATED_FRAMES + 1 not in (2, 4, 8, 16, 32, 64, 128):\n",
        "    raise ValueError(\"MAX_INTERPOLATED_FRAMES + 1 must be a power of 2\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "6iPjfJwa3k2j"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-02-10 21:48:26.401972: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2025-02-10 21:48:26.402015: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2025-02-10 21:48:26.402689: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-02-10 21:48:26.406735: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2025-02-10 21:48:27.176604: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "/home/sparsh/miniconda3/envs/gputf/lib/python3.10/site-packages/numba/np/ufunc/parallel.py:371: NumbaWarning: \u001b[1mThe TBB threading layer requires TBB version 2021 update 6 or later i.e., TBB_INTERFACE_VERSION >= 12060. Found TBB_INTERFACE_VERSION = 12050. The TBB threading layer is disabled.\u001b[0m\n",
            "  warnings.warn(problem)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model file already exists\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import tempfile\n",
        "import tensorflow as tf\n",
        "import mediapy\n",
        "import cv2\n",
        "from PIL import Image, ExifTags\n",
        "import re\n",
        "\n",
        "from natsort import natsorted\n",
        "import shutil\n",
        "from tqdm import tqdm\n",
        "from datetime import datetime\n",
        "import subprocess\n",
        "import math\n",
        "import mediapy as media\n",
        "import sys\n",
        "from typing import Generator, Iterable, List, Optional\n",
        "\n",
        "\n",
        "from eval import interpolator, util\n",
        "import fix_images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "snJNybSe3k2j"
      },
      "source": [
        "## Config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "sDVZ3dQR3k2k",
        "outputId": "4deec4f3-e72d-4778-e7ca-da4104c8a71e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model already downloaded\n"
          ]
        }
      ],
      "source": [
        "# Download the pretrained model\n",
        "import gdown\n",
        "os.makedirs('pretrained_models/film_net/Style/saved_model', exist_ok=True)\n",
        "\n",
        "if os.path.exists('pretrained_models/film_net/Style/saved_model/saved_model.pb'):\n",
        "    print('Model already downloaded')\n",
        "else:\n",
        "  folder_url = 'https://drive.google.com/drive/folders/1i9Go1YI2qiFWeT5QtywNFmYAA74bhXWj'\n",
        "  gdown.download_folder(folder_url, output='pretrained_models/film_net/Style/saved_model', quiet=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wgpvI8G83k2k"
      },
      "source": [
        "## Plan"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "dVhGZ5ct3k2k"
      },
      "outputs": [],
      "source": [
        "# 1. Preprocess images\n",
        "# 2. for succesive pairs of images:\n",
        "# 3.     generate interpolated frames\n",
        "# 4.     add interpolated frames to the output directory\n",
        "# 5. generate video from output directory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3WIJ6zNr3k2k"
      },
      "source": [
        "## Utility Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "peMfh7q33k2k"
      },
      "outputs": [],
      "source": [
        "\n",
        "# create empty output directory\n",
        "def create_empty_dir(dir_name):\n",
        "  if os.path.exists(dir_name):\n",
        "    shutil.rmtree(dir_name)\n",
        "  os.makedirs(dir_name)\n",
        "\n",
        "\n",
        "def resize_and_save(input_path, output_path, size):\n",
        "  if input_path.lower().endswith(VALID_IMG_FORMATS):\n",
        "      img = Image.open(input_path)\n",
        "      img = img.resize(size, Image.Resampling.LANCZOS)\n",
        "      img.save(output_path)\n",
        "  else:\n",
        "      raise ValueError(f'Unsupported file format: {input_path}')\n",
        "\n",
        "\n",
        "def get_sorted_images(input_dir: str) -> Path:\n",
        "    input_dir = Path(input_dir)\n",
        "    image_files = [\n",
        "        f.as_posix() for f in input_dir.iterdir()\n",
        "        if f.is_file() and f.suffix.lower() in VALID_IMG_FORMATS\n",
        "    ]\n",
        "    \n",
        "    # Sort files naturally\n",
        "    image_files = natsorted(image_files)\n",
        "\n",
        "    # image_files = natsorted([f for f in os.listdir(input_dir) if f.lower().endswith(VALID_IMG_FORMATS)])\n",
        "    if not image_files:\n",
        "        raise Exception(\"No images found in the directory.\", input_dir)\n",
        "    return image_files\n",
        "    \n",
        "\n",
        "# prepare input data\n",
        "def prepare_images(input_dir, processed_input_dir, preprocess_faces, size, reference_img_name=None, fix_lighting=False):\n",
        "    files = get_sorted_images(input_dir)\n",
        "  \n",
        "    # find the reference image\n",
        "    if reference_img_name == '':\n",
        "        reference_path = files[0]\n",
        "    else:\n",
        "        reference_path = None\n",
        "        for f in files:\n",
        "            image_path = Path(f)\n",
        "            if image_path.name == reference_img_name:\n",
        "                reference_path = image_path.with_name(reference_img_name)\n",
        "                break\n",
        "            elif str(image_path) == reference_img_name:\n",
        "                reference_path = image_path\n",
        "                break\n",
        "            else:\n",
        "                continue\n",
        "        if reference_path is None:\n",
        "            raise Exception('Reference image not found')\n",
        "    \n",
        "    print('reference_image', str(reference_path))\n",
        "\n",
        "    for f in tqdm(files, desc='Preparing images'):\n",
        "        output_file = (Path(processed_input_dir) / Path(f).name).as_posix()\n",
        "        if preprocess_faces:\n",
        "            fix_images.process_face_image(\n",
        "                f,\n",
        "                output_file,\n",
        "                reference_path=str(reference_path),\n",
        "                background_color=(255, 255, 255),  # White background\n",
        "                save_bbox_preview=False,\n",
        "                fix_lighting=fix_lighting\n",
        "                )\n",
        "        else:\n",
        "            resize_and_save(f, output_file, size)\n",
        "\n",
        "\n",
        "def get_new_size(image_path: str, max_dim: int = MAX_DIM) -> np.ndarray:\n",
        "    \"\"\"Resize the image so that the maximum dimension is `max_dim`.\"\"\"\n",
        "    image = cv2.imread(image_path)\n",
        "    h, w = image.shape[:2]\n",
        "    if h > w:\n",
        "        new_h = max_dim\n",
        "        new_w = int(w * new_h / h)\n",
        "    else:\n",
        "        new_w = max_dim\n",
        "        new_h = int(h * new_w / w)\n",
        "    return (new_w, new_h)\n",
        "\n",
        "\n",
        "def string_to_timestamp(datetime_str):\n",
        "    # Try yyyymmdd_hhmmss pattern\n",
        "    pattern1 = r'(\\d{8}_\\d{6})'\n",
        "    match = re.search(pattern1, datetime_str)\n",
        "    if match:\n",
        "        try:\n",
        "            return datetime.strptime(match.group(1), \"%Y%m%d_%H%M%S\")\n",
        "        except ValueError:\n",
        "            pass\n",
        "\n",
        "    # Try yyyymmdd pattern\n",
        "    pattern2 = r'(\\d{8})'\n",
        "    match = re.search(pattern2, datetime_str)\n",
        "    if match:\n",
        "        try:\n",
        "            return datetime.strptime(match.group(1), \"%Y%m%d\")\n",
        "        except ValueError:\n",
        "            pass\n",
        "\n",
        "    raise ValueError(\"No valid date found in string. Expected format: YYYYMMDD or YYYYMMDD_HHMMSS\")\n",
        "\n",
        "\n",
        "def timestamp_to_string(timestamp):\n",
        "    # Convert the timestamp number to a datetime object\n",
        "    dt = datetime.fromtimestamp(timestamp)\n",
        "    # Format the datetime object to the desired string format\n",
        "    formatted_string = dt.strftime(\"%Y%m%d_%H%M%S\")\n",
        "    return formatted_string\n",
        "\n",
        "\n",
        "def choose_evenly_spaced_timestamps(timestamps, k):\n",
        "    # Ensure we have at least k timestamps\n",
        "    if k > len(timestamps):\n",
        "        raise ValueError(\"k cannot be greater than the number of timestamps\")\n",
        "\n",
        "    # Calculate the interval between timestamps\n",
        "    n = len(timestamps)\n",
        "    interval = (n - 1) / (k - 1)\n",
        "\n",
        "    # Select the timestamps\n",
        "    chosen_timestamps = []\n",
        "    for i in range(k):\n",
        "        index = round(i * interval)\n",
        "        chosen_timestamps.append(timestamps[index])\n",
        "\n",
        "    return chosen_timestamps\n",
        "\n",
        "\n",
        "def save_video(frames, out_path):\n",
        "    ffmpeg_path = util.get_ffmpeg_path()\n",
        "    mediapy.set_ffmpeg(ffmpeg_path)\n",
        "    mediapy.write_video(out_path, frames, fps=30)\n",
        "\n",
        "\n",
        "def save_frames(frames, output_dir, format='jpg'):\n",
        "    \"\"\"\n",
        "    Save interpolated frames to the specified output directory and return the output paths.\n",
        "    Args:\n",
        "        frames: List of image arrays\n",
        "        output_dir: Directory to save frames\n",
        "        format: Image format to save (jpg/png)\n",
        "    Returns:\n",
        "        list: List of file paths where the frames are saved.\n",
        "    \"\"\"\n",
        "    output_paths = []\n",
        "    for idx, frame in enumerate(frames):\n",
        "        output_path = os.path.join(output_dir, f'frame_{idx:06d}.{format}')\n",
        "        util.write_image(output_path, frame)\n",
        "        output_paths.append(output_path)\n",
        "    return output_paths\n",
        "\n",
        "\n",
        "\n",
        "def write_video_from_images(image_dir, output_path, fps):\n",
        "    image_files = get_sorted_images(image_dir)\n",
        "    \n",
        "    # Read the first image to get the dimensions\n",
        "    first_image_path = image_files[0]\n",
        "    first_frame = cv2.imread(first_image_path)\n",
        "    height, width, layers = first_frame.shape\n",
        "    \n",
        "    # Initialize the video writer\n",
        "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # Specify the codec\n",
        "    video_writer = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
        "    \n",
        "    for image_file in image_files:\n",
        "        frame = cv2.imread(image_file)\n",
        "        if frame is None:\n",
        "            print(f\"Skipping {image_file}, cannot read image.\")\n",
        "            continue\n",
        "        video_writer.write(frame)\n",
        "    \n",
        "    video_writer.release()\n",
        "    print(f\"Video saved to: {output_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "3xUYjgHd3k2k"
      },
      "outputs": [],
      "source": [
        "\n",
        "def interpolate_frames(image_1, image_2, times_to_interpolate, interpolator):\n",
        "  input_frames = [str(image_1), str(image_2)]\n",
        "\n",
        "  frames = list(\n",
        "      util.interpolate_recursively_from_files(\n",
        "          input_frames, times_to_interpolate, interpolator))\n",
        "  return frames"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qNI760nM3k2l"
      },
      "source": [
        "## Main"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gzC7E2oK3k2l",
        "outputId": "fd84bc90-10e5-44e1-be08-30aebb1d4247"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1992_deewana.jpg\n",
            "1993_baazigar.jpg\n",
            "1995_ddlj.jpg\n",
            "1998_kuch_kuch_hota_hai.jpg\n",
            "2001_kbkg.jpg\n",
            "2003_kal_ho_na_ho.jpeg\n",
            "2006_kabh_alvida.jpg\n",
            "2009_billu.jpg\n",
            "2011_don.jpg\n",
            "2014_hny.jpg\n",
            "2017_raees.jpg\n",
            "2019_media.jpg\n",
            "2023_pathan.jpg\n"
          ]
        }
      ],
      "source": [
        "# Preprocess images\n",
        "\n",
        "processed_input_dir = tempfile.mkdtemp()\n",
        "temp_interpolated_frames_dir = tempfile.mkdtemp()\n",
        "\n",
        "files = get_sorted_images(INPUT_DIR)\n",
        "for f in files:\n",
        "    print(Path(f).name)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "reference_image input_frames/shahrukh-khan/2017_raees.jpg\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Preparing images:   0%|          | 0/13 [00:00<?, ?it/s]INFO:fix_images:Processing image: input_frames/shahrukh-khan/1992_deewana.jpg\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:fix_images:Image loaded successfully\n",
            "libEGL warning: MESA-LOADER: failed to open swrast: /usr/lib/dri/swrast_dri.so: cannot open shared object file: No such file or directory (search paths /usr/lib/x86_64-linux-gnu/dri:\\$${ORIGIN}/dri:/usr/lib/dri, suffix _dri)\n",
            "\n",
            "libEGL warning: MESA-LOADER: failed to open swrast: /usr/lib/dri/swrast_dri.so: cannot open shared object file: No such file or directory (search paths /usr/lib/x86_64-linux-gnu/dri:\\$${ORIGIN}/dri:/usr/lib/dri, suffix _dri)\n",
            "\n",
            "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "W0000 00:00:1739204389.990509   17660 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
            "INFO:fix_images:Face detected successfully\n",
            "INFO:fix_images:Image cropped and centered\n",
            "INFO:fix_images:Image resized\n",
            "INFO:fix_images:Background removed\n",
            "libEGL warning: MESA-LOADER: failed to open swrast: /usr/lib/dri/swrast_dri.so: cannot open shared object file: No such file or directory (search paths /usr/lib/x86_64-linux-gnu/dri:\\$${ORIGIN}/dri:/usr/lib/dri, suffix _dri)\n",
            "\n",
            "libEGL warning: MESA-LOADER: failed to open swrast: /usr/lib/dri/swrast_dri.so: cannot open shared object file: No such file or directory (search paths /usr/lib/x86_64-linux-gnu/dri:\\$${ORIGIN}/dri:/usr/lib/dri, suffix _dri)\n",
            "\n",
            "W0000 00:00:1739204391.657120   17681 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
            "INFO:fix_images:Processed image saved to: /tmp/tmp3235fmkm/1992_deewana.jpg\n",
            "Preparing images:   8%|▊         | 1/13 [00:02<00:29,  2.49s/it]INFO:fix_images:Processing image: input_frames/shahrukh-khan/1993_baazigar.jpg\n",
            "INFO:fix_images:Image loaded successfully\n",
            "libEGL warning: MESA-LOADER: failed to open swrast: /usr/lib/dri/swrast_dri.so: cannot open shared object file: No such file or directory (search paths /usr/lib/x86_64-linux-gnu/dri:\\$${ORIGIN}/dri:/usr/lib/dri, suffix _dri)\n",
            "\n",
            "libEGL warning: MESA-LOADER: failed to open swrast: /usr/lib/dri/swrast_dri.so: cannot open shared object file: No such file or directory (search paths /usr/lib/x86_64-linux-gnu/dri:\\$${ORIGIN}/dri:/usr/lib/dri, suffix _dri)\n",
            "\n",
            "W0000 00:00:1739204392.430981   17695 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
            "INFO:fix_images:Face detected successfully\n",
            "INFO:fix_images:Image cropped and centered\n",
            "INFO:fix_images:Image resized\n",
            "INFO:fix_images:Background removed\n",
            "libEGL warning: MESA-LOADER: failed to open swrast: /usr/lib/dri/swrast_dri.so: cannot open shared object file: No such file or directory (search paths /usr/lib/x86_64-linux-gnu/dri:\\$${ORIGIN}/dri:/usr/lib/dri, suffix _dri)\n",
            "\n",
            "libEGL warning: MESA-LOADER: failed to open swrast: /usr/lib/dri/swrast_dri.so: cannot open shared object file: No such file or directory (search paths /usr/lib/x86_64-linux-gnu/dri:\\$${ORIGIN}/dri:/usr/lib/dri, suffix _dri)\n",
            "\n",
            "W0000 00:00:1739204393.726165   17714 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
            "INFO:fix_images:Processed image saved to: /tmp/tmp3235fmkm/1993_baazigar.jpg\n",
            "Preparing images:  15%|█▌        | 2/13 [00:04<00:24,  2.22s/it]INFO:fix_images:Processing image: input_frames/shahrukh-khan/1995_ddlj.jpg\n",
            "INFO:fix_images:Image loaded successfully\n",
            "libEGL warning: MESA-LOADER: failed to open swrast: /usr/lib/dri/swrast_dri.so: cannot open shared object file: No such file or directory (search paths /usr/lib/x86_64-linux-gnu/dri:\\$${ORIGIN}/dri:/usr/lib/dri, suffix _dri)\n",
            "\n",
            "libEGL warning: MESA-LOADER: failed to open swrast: /usr/lib/dri/swrast_dri.so: cannot open shared object file: No such file or directory (search paths /usr/lib/x86_64-linux-gnu/dri:\\$${ORIGIN}/dri:/usr/lib/dri, suffix _dri)\n",
            "\n",
            "W0000 00:00:1739204394.476267   17730 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
            "INFO:fix_images:Face detected successfully\n",
            "INFO:fix_images:Image cropped and centered\n",
            "INFO:fix_images:Image resized\n",
            "INFO:fix_images:Background removed\n",
            "libEGL warning: MESA-LOADER: failed to open swrast: /usr/lib/dri/swrast_dri.so: cannot open shared object file: No such file or directory (search paths /usr/lib/x86_64-linux-gnu/dri:\\$${ORIGIN}/dri:/usr/lib/dri, suffix _dri)\n",
            "\n",
            "libEGL warning: MESA-LOADER: failed to open swrast: /usr/lib/dri/swrast_dri.so: cannot open shared object file: No such file or directory (search paths /usr/lib/x86_64-linux-gnu/dri:\\$${ORIGIN}/dri:/usr/lib/dri, suffix _dri)\n",
            "\n",
            "W0000 00:00:1739204395.813658   17749 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
            "INFO:fix_images:Processed image saved to: /tmp/tmp3235fmkm/1995_ddlj.jpg\n",
            "Preparing images:  23%|██▎       | 3/13 [00:06<00:21,  2.15s/it]INFO:fix_images:Processing image: input_frames/shahrukh-khan/1998_kuch_kuch_hota_hai.jpg\n",
            "INFO:fix_images:Image loaded successfully\n",
            "libEGL warning: MESA-LOADER: failed to open swrast: /usr/lib/dri/swrast_dri.so: cannot open shared object file: No such file or directory (search paths /usr/lib/x86_64-linux-gnu/dri:\\$${ORIGIN}/dri:/usr/lib/dri, suffix _dri)\n",
            "\n",
            "libEGL warning: MESA-LOADER: failed to open swrast: /usr/lib/dri/swrast_dri.so: cannot open shared object file: No such file or directory (search paths /usr/lib/x86_64-linux-gnu/dri:\\$${ORIGIN}/dri:/usr/lib/dri, suffix _dri)\n",
            "\n",
            "W0000 00:00:1739204396.531199   17766 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
            "INFO:fix_images:Face detected successfully\n",
            "INFO:fix_images:Image cropped and centered\n",
            "INFO:fix_images:Image resized\n",
            "INFO:fix_images:Background removed\n",
            "libEGL warning: MESA-LOADER: failed to open swrast: /usr/lib/dri/swrast_dri.so: cannot open shared object file: No such file or directory (search paths /usr/lib/x86_64-linux-gnu/dri:\\$${ORIGIN}/dri:/usr/lib/dri, suffix _dri)\n",
            "\n",
            "libEGL warning: MESA-LOADER: failed to open swrast: /usr/lib/dri/swrast_dri.so: cannot open shared object file: No such file or directory (search paths /usr/lib/x86_64-linux-gnu/dri:\\$${ORIGIN}/dri:/usr/lib/dri, suffix _dri)\n",
            "\n",
            "W0000 00:00:1739204397.868635   17789 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
            "INFO:fix_images:Processed image saved to: /tmp/tmp3235fmkm/1998_kuch_kuch_hota_hai.jpg\n",
            "Preparing images:  31%|███       | 4/13 [00:08<00:19,  2.11s/it]INFO:fix_images:Processing image: input_frames/shahrukh-khan/2001_kbkg.jpg\n",
            "INFO:fix_images:Image loaded successfully\n",
            "libEGL warning: MESA-LOADER: failed to open swrast: /usr/lib/dri/swrast_dri.so: cannot open shared object file: No such file or directory (search paths /usr/lib/x86_64-linux-gnu/dri:\\$${ORIGIN}/dri:/usr/lib/dri, suffix _dri)\n",
            "\n",
            "libEGL warning: MESA-LOADER: failed to open swrast: /usr/lib/dri/swrast_dri.so: cannot open shared object file: No such file or directory (search paths /usr/lib/x86_64-linux-gnu/dri:\\$${ORIGIN}/dri:/usr/lib/dri, suffix _dri)\n",
            "\n",
            "W0000 00:00:1739204398.592287   17803 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
            "INFO:fix_images:Face detected successfully\n",
            "INFO:fix_images:Image cropped and centered\n",
            "INFO:fix_images:Image resized\n",
            "INFO:fix_images:Background removed\n",
            "libEGL warning: MESA-LOADER: failed to open swrast: /usr/lib/dri/swrast_dri.so: cannot open shared object file: No such file or directory (search paths /usr/lib/x86_64-linux-gnu/dri:\\$${ORIGIN}/dri:/usr/lib/dri, suffix _dri)\n",
            "\n",
            "libEGL warning: MESA-LOADER: failed to open swrast: /usr/lib/dri/swrast_dri.so: cannot open shared object file: No such file or directory (search paths /usr/lib/x86_64-linux-gnu/dri:\\$${ORIGIN}/dri:/usr/lib/dri, suffix _dri)\n",
            "\n",
            "W0000 00:00:1739204399.916855   17823 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
            "INFO:fix_images:Processed image saved to: /tmp/tmp3235fmkm/2001_kbkg.jpg\n",
            "Preparing images:  38%|███▊      | 5/13 [00:10<00:16,  2.11s/it]INFO:fix_images:Processing image: input_frames/shahrukh-khan/2003_kal_ho_na_ho.jpeg\n",
            "INFO:fix_images:Image loaded successfully\n",
            "libEGL warning: MESA-LOADER: failed to open swrast: /usr/lib/dri/swrast_dri.so: cannot open shared object file: No such file or directory (search paths /usr/lib/x86_64-linux-gnu/dri:\\$${ORIGIN}/dri:/usr/lib/dri, suffix _dri)\n",
            "\n",
            "libEGL warning: MESA-LOADER: failed to open swrast: /usr/lib/dri/swrast_dri.so: cannot open shared object file: No such file or directory (search paths /usr/lib/x86_64-linux-gnu/dri:\\$${ORIGIN}/dri:/usr/lib/dri, suffix _dri)\n",
            "\n",
            "W0000 00:00:1739204400.679694   17839 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
            "INFO:fix_images:Face detected successfully\n",
            "INFO:fix_images:Image cropped and centered\n",
            "INFO:fix_images:Image resized\n",
            "INFO:fix_images:Background removed\n",
            "libEGL warning: MESA-LOADER: failed to open swrast: /usr/lib/dri/swrast_dri.so: cannot open shared object file: No such file or directory (search paths /usr/lib/x86_64-linux-gnu/dri:\\$${ORIGIN}/dri:/usr/lib/dri, suffix _dri)\n",
            "\n",
            "libEGL warning: MESA-LOADER: failed to open swrast: /usr/lib/dri/swrast_dri.so: cannot open shared object file: No such file or directory (search paths /usr/lib/x86_64-linux-gnu/dri:\\$${ORIGIN}/dri:/usr/lib/dri, suffix _dri)\n",
            "\n",
            "W0000 00:00:1739204401.980679   17857 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
            "INFO:fix_images:Processed image saved to: /tmp/tmp3235fmkm/2003_kal_ho_na_ho.jpeg\n",
            "Preparing images:  46%|████▌     | 6/13 [00:12<00:14,  2.08s/it]INFO:fix_images:Processing image: input_frames/shahrukh-khan/2006_kabh_alvida.jpg\n",
            "INFO:fix_images:Image loaded successfully\n",
            "libEGL warning: MESA-LOADER: failed to open swrast: /usr/lib/dri/swrast_dri.so: cannot open shared object file: No such file or directory (search paths /usr/lib/x86_64-linux-gnu/dri:\\$${ORIGIN}/dri:/usr/lib/dri, suffix _dri)\n",
            "\n",
            "libEGL warning: MESA-LOADER: failed to open swrast: /usr/lib/dri/swrast_dri.so: cannot open shared object file: No such file or directory (search paths /usr/lib/x86_64-linux-gnu/dri:\\$${ORIGIN}/dri:/usr/lib/dri, suffix _dri)\n",
            "\n",
            "W0000 00:00:1739204402.697515   17874 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
            "INFO:fix_images:Face detected successfully\n",
            "INFO:fix_images:Image cropped and centered\n",
            "INFO:fix_images:Image resized\n",
            "INFO:fix_images:Background removed\n",
            "libEGL warning: MESA-LOADER: failed to open swrast: /usr/lib/dri/swrast_dri.so: cannot open shared object file: No such file or directory (search paths /usr/lib/x86_64-linux-gnu/dri:\\$${ORIGIN}/dri:/usr/lib/dri, suffix _dri)\n",
            "\n",
            "libEGL warning: MESA-LOADER: failed to open swrast: /usr/lib/dri/swrast_dri.so: cannot open shared object file: No such file or directory (search paths /usr/lib/x86_64-linux-gnu/dri:\\$${ORIGIN}/dri:/usr/lib/dri, suffix _dri)\n",
            "\n",
            "W0000 00:00:1739204404.003366   17892 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
            "INFO:fix_images:Processed image saved to: /tmp/tmp3235fmkm/2006_kabh_alvida.jpg\n",
            "Preparing images:  54%|█████▍    | 7/13 [00:14<00:12,  2.06s/it]INFO:fix_images:Processing image: input_frames/shahrukh-khan/2009_billu.jpg\n",
            "INFO:fix_images:Image loaded successfully\n",
            "libEGL warning: MESA-LOADER: failed to open swrast: /usr/lib/dri/swrast_dri.so: cannot open shared object file: No such file or directory (search paths /usr/lib/x86_64-linux-gnu/dri:\\$${ORIGIN}/dri:/usr/lib/dri, suffix _dri)\n",
            "\n",
            "libEGL warning: MESA-LOADER: failed to open swrast: /usr/lib/dri/swrast_dri.so: cannot open shared object file: No such file or directory (search paths /usr/lib/x86_64-linux-gnu/dri:\\$${ORIGIN}/dri:/usr/lib/dri, suffix _dri)\n",
            "\n",
            "W0000 00:00:1739204404.740401   17908 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
            "INFO:fix_images:Face detected successfully\n",
            "INFO:fix_images:Image cropped and centered\n",
            "INFO:fix_images:Image resized\n",
            "INFO:fix_images:Background removed\n",
            "libEGL warning: MESA-LOADER: failed to open swrast: /usr/lib/dri/swrast_dri.so: cannot open shared object file: No such file or directory (search paths /usr/lib/x86_64-linux-gnu/dri:\\$${ORIGIN}/dri:/usr/lib/dri, suffix _dri)\n",
            "\n",
            "libEGL warning: MESA-LOADER: failed to open swrast: /usr/lib/dri/swrast_dri.so: cannot open shared object file: No such file or directory (search paths /usr/lib/x86_64-linux-gnu/dri:\\$${ORIGIN}/dri:/usr/lib/dri, suffix _dri)\n",
            "\n",
            "W0000 00:00:1739204406.056983   17929 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
            "INFO:fix_images:Processed image saved to: /tmp/tmp3235fmkm/2009_billu.jpg\n",
            "Preparing images:  62%|██████▏   | 8/13 [00:16<00:10,  2.07s/it]INFO:fix_images:Processing image: input_frames/shahrukh-khan/2011_don.jpg\n",
            "INFO:fix_images:Image loaded successfully\n",
            "libEGL warning: MESA-LOADER: failed to open swrast: /usr/lib/dri/swrast_dri.so: cannot open shared object file: No such file or directory (search paths /usr/lib/x86_64-linux-gnu/dri:\\$${ORIGIN}/dri:/usr/lib/dri, suffix _dri)\n",
            "\n",
            "libEGL warning: MESA-LOADER: failed to open swrast: /usr/lib/dri/swrast_dri.so: cannot open shared object file: No such file or directory (search paths /usr/lib/x86_64-linux-gnu/dri:\\$${ORIGIN}/dri:/usr/lib/dri, suffix _dri)\n",
            "\n",
            "W0000 00:00:1739204406.825092   17944 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
            "INFO:fix_images:Face detected successfully\n",
            "INFO:fix_images:Image cropped and centered\n",
            "INFO:fix_images:Image resized\n",
            "INFO:fix_images:Background removed\n",
            "libEGL warning: MESA-LOADER: failed to open swrast: /usr/lib/dri/swrast_dri.so: cannot open shared object file: No such file or directory (search paths /usr/lib/x86_64-linux-gnu/dri:\\$${ORIGIN}/dri:/usr/lib/dri, suffix _dri)\n",
            "\n",
            "libEGL warning: MESA-LOADER: failed to open swrast: /usr/lib/dri/swrast_dri.so: cannot open shared object file: No such file or directory (search paths /usr/lib/x86_64-linux-gnu/dri:\\$${ORIGIN}/dri:/usr/lib/dri, suffix _dri)\n",
            "\n",
            "W0000 00:00:1739204408.107621   17964 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
            "INFO:fix_images:Processed image saved to: /tmp/tmp3235fmkm/2011_don.jpg\n",
            "Preparing images:  69%|██████▉   | 9/13 [00:18<00:08,  2.05s/it]INFO:fix_images:Processing image: input_frames/shahrukh-khan/2014_hny.jpg\n",
            "INFO:fix_images:Image loaded successfully\n",
            "libEGL warning: MESA-LOADER: failed to open swrast: /usr/lib/dri/swrast_dri.so: cannot open shared object file: No such file or directory (search paths /usr/lib/x86_64-linux-gnu/dri:\\$${ORIGIN}/dri:/usr/lib/dri, suffix _dri)\n",
            "\n",
            "libEGL warning: MESA-LOADER: failed to open swrast: /usr/lib/dri/swrast_dri.so: cannot open shared object file: No such file or directory (search paths /usr/lib/x86_64-linux-gnu/dri:\\$${ORIGIN}/dri:/usr/lib/dri, suffix _dri)\n",
            "\n",
            "W0000 00:00:1739204408.825134   17980 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
            "INFO:fix_images:Face detected successfully\n",
            "INFO:fix_images:Image cropped and centered\n",
            "INFO:fix_images:Image resized\n",
            "INFO:fix_images:Background removed\n",
            "libEGL warning: MESA-LOADER: failed to open swrast: /usr/lib/dri/swrast_dri.so: cannot open shared object file: No such file or directory (search paths /usr/lib/x86_64-linux-gnu/dri:\\$${ORIGIN}/dri:/usr/lib/dri, suffix _dri)\n",
            "\n",
            "libEGL warning: MESA-LOADER: failed to open swrast: /usr/lib/dri/swrast_dri.so: cannot open shared object file: No such file or directory (search paths /usr/lib/x86_64-linux-gnu/dri:\\$${ORIGIN}/dri:/usr/lib/dri, suffix _dri)\n",
            "\n",
            "W0000 00:00:1739204410.128897   17997 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
            "INFO:fix_images:Processed image saved to: /tmp/tmp3235fmkm/2014_hny.jpg\n",
            "Preparing images:  77%|███████▋  | 10/13 [00:20<00:06,  2.04s/it]INFO:fix_images:Processing image: input_frames/shahrukh-khan/2017_raees.jpg\n",
            "INFO:fix_images:Image loaded successfully\n",
            "libEGL warning: MESA-LOADER: failed to open swrast: /usr/lib/dri/swrast_dri.so: cannot open shared object file: No such file or directory (search paths /usr/lib/x86_64-linux-gnu/dri:\\$${ORIGIN}/dri:/usr/lib/dri, suffix _dri)\n",
            "\n",
            "libEGL warning: MESA-LOADER: failed to open swrast: /usr/lib/dri/swrast_dri.so: cannot open shared object file: No such file or directory (search paths /usr/lib/x86_64-linux-gnu/dri:\\$${ORIGIN}/dri:/usr/lib/dri, suffix _dri)\n",
            "\n",
            "W0000 00:00:1739204410.847110   18013 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
            "INFO:fix_images:Face detected successfully\n",
            "INFO:fix_images:Image cropped and centered\n",
            "INFO:fix_images:Image resized\n",
            "INFO:fix_images:Background removed\n",
            "libEGL warning: MESA-LOADER: failed to open swrast: /usr/lib/dri/swrast_dri.so: cannot open shared object file: No such file or directory (search paths /usr/lib/x86_64-linux-gnu/dri:\\$${ORIGIN}/dri:/usr/lib/dri, suffix _dri)\n",
            "\n",
            "libEGL warning: MESA-LOADER: failed to open swrast: /usr/lib/dri/swrast_dri.so: cannot open shared object file: No such file or directory (search paths /usr/lib/x86_64-linux-gnu/dri:\\$${ORIGIN}/dri:/usr/lib/dri, suffix _dri)\n",
            "\n",
            "W0000 00:00:1739204412.142513   18033 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
            "INFO:fix_images:Processed image saved to: /tmp/tmp3235fmkm/2017_raees.jpg\n",
            "Preparing images:  85%|████████▍ | 11/13 [00:22<00:04,  2.04s/it]INFO:fix_images:Processing image: input_frames/shahrukh-khan/2019_media.jpg\n",
            "INFO:fix_images:Image loaded successfully\n",
            "libEGL warning: MESA-LOADER: failed to open swrast: /usr/lib/dri/swrast_dri.so: cannot open shared object file: No such file or directory (search paths /usr/lib/x86_64-linux-gnu/dri:\\$${ORIGIN}/dri:/usr/lib/dri, suffix _dri)\n",
            "\n",
            "libEGL warning: MESA-LOADER: failed to open swrast: /usr/lib/dri/swrast_dri.so: cannot open shared object file: No such file or directory (search paths /usr/lib/x86_64-linux-gnu/dri:\\$${ORIGIN}/dri:/usr/lib/dri, suffix _dri)\n",
            "\n",
            "W0000 00:00:1739204412.888070   18049 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
            "INFO:fix_images:Face detected successfully\n",
            "INFO:fix_images:Image cropped and centered\n",
            "INFO:fix_images:Image resized\n",
            "INFO:fix_images:Background removed\n",
            "libEGL warning: MESA-LOADER: failed to open swrast: /usr/lib/dri/swrast_dri.so: cannot open shared object file: No such file or directory (search paths /usr/lib/x86_64-linux-gnu/dri:\\$${ORIGIN}/dri:/usr/lib/dri, suffix _dri)\n",
            "\n",
            "libEGL warning: MESA-LOADER: failed to open swrast: /usr/lib/dri/swrast_dri.so: cannot open shared object file: No such file or directory (search paths /usr/lib/x86_64-linux-gnu/dri:\\$${ORIGIN}/dri:/usr/lib/dri, suffix _dri)\n",
            "\n",
            "W0000 00:00:1739204414.199828   18067 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
            "INFO:fix_images:Processed image saved to: /tmp/tmp3235fmkm/2019_media.jpg\n",
            "Preparing images:  92%|█████████▏| 12/13 [00:24<00:02,  2.03s/it]INFO:fix_images:Processing image: input_frames/shahrukh-khan/2023_pathan.jpg\n",
            "INFO:fix_images:Image loaded successfully\n",
            "libEGL warning: MESA-LOADER: failed to open swrast: /usr/lib/dri/swrast_dri.so: cannot open shared object file: No such file or directory (search paths /usr/lib/x86_64-linux-gnu/dri:\\$${ORIGIN}/dri:/usr/lib/dri, suffix _dri)\n",
            "\n",
            "libEGL warning: MESA-LOADER: failed to open swrast: /usr/lib/dri/swrast_dri.so: cannot open shared object file: No such file or directory (search paths /usr/lib/x86_64-linux-gnu/dri:\\$${ORIGIN}/dri:/usr/lib/dri, suffix _dri)\n",
            "\n",
            "W0000 00:00:1739204414.919233   18083 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
            "INFO:fix_images:Face detected successfully\n",
            "INFO:fix_images:Image cropped and centered\n",
            "INFO:fix_images:Image resized\n",
            "INFO:fix_images:Background removed\n",
            "libEGL warning: MESA-LOADER: failed to open swrast: /usr/lib/dri/swrast_dri.so: cannot open shared object file: No such file or directory (search paths /usr/lib/x86_64-linux-gnu/dri:\\$${ORIGIN}/dri:/usr/lib/dri, suffix _dri)\n",
            "\n",
            "libEGL warning: MESA-LOADER: failed to open swrast: /usr/lib/dri/swrast_dri.so: cannot open shared object file: No such file or directory (search paths /usr/lib/x86_64-linux-gnu/dri:\\$${ORIGIN}/dri:/usr/lib/dri, suffix _dri)\n",
            "\n",
            "W0000 00:00:1739204416.272409   18104 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
            "INFO:fix_images:Processed image saved to: /tmp/tmp3235fmkm/2023_pathan.jpg\n",
            "Preparing images: 100%|██████████| 13/13 [00:27<00:00,  2.08s/it]\n"
          ]
        }
      ],
      "source": [
        "new_size = get_new_size(files[0])\n",
        "create_empty_dir(processed_input_dir)\n",
        "prepare_images(INPUT_DIR, processed_input_dir, preprocess_faces, new_size, reference_img_name=REFERENCE_IMG_NAME, fix_lighting=FIX_LIGHTING)\n",
        "files = get_sorted_images(processed_input_dir)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "preprocessed images in /tmp/tmp3235fmkm\n",
            "file count 13\n"
          ]
        }
      ],
      "source": [
        "print('preprocessed images in', processed_input_dir)\n",
        "print('file count', len(files))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u5gnR-pS3k2l",
        "outputId": "5a23d5eb-8847-447d-9bda-ce95caa4d138"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Filename: 1992_deewana.jpg\n",
            "Filename: 1993_baazigar.jpg\n",
            "Filename: 1995_ddlj.jpg\n",
            "Filename: 1998_kuch_kuch_hota_hai.jpg\n",
            "Filename: 2001_kbkg.jpg\n",
            "Filename: 2003_kal_ho_na_ho.jpeg\n",
            "Filename: 2006_kabh_alvida.jpg\n",
            "Filename: 2009_billu.jpg\n",
            "Filename: 2011_don.jpg\n",
            "Filename: 2014_hny.jpg\n",
            "Filename: 2017_raees.jpg\n",
            "Filename: 2019_media.jpg\n",
            "Filename: 2023_pathan.jpg\n"
          ]
        }
      ],
      "source": [
        "if not equal_intervals:\n",
        "    for file in files:\n",
        "      \n",
        "      timestamp = string_to_timestamp(Path(file).stem)\n",
        "      print(f\"Filename: {file}, Datetime: {timestamp}\")\n",
        "else:\n",
        "   for file in files:\n",
        "      print(f\"Filename: {file}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "344GgQzX3k2l",
        "outputId": "b1736c9e-089b-4013-8a28-8a55e63e1e13"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-02-10 21:55:00.247774: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
            "Your kernel may have been built without NUMA support.\n",
            "2025-02-10 21:55:00.260857: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
            "Your kernel may have been built without NUMA support.\n",
            "2025-02-10 21:55:00.260974: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
            "Your kernel may have been built without NUMA support.\n",
            "2025-02-10 21:55:00.263562: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
            "Your kernel may have been built without NUMA support.\n",
            "2025-02-10 21:55:00.263610: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
            "Your kernel may have been built without NUMA support.\n",
            "2025-02-10 21:55:00.263629: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
            "Your kernel may have been built without NUMA support.\n",
            "2025-02-10 21:55:00.439570: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
            "Your kernel may have been built without NUMA support.\n",
            "2025-02-10 21:55:00.439676: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
            "Your kernel may have been built without NUMA support.\n",
            "2025-02-10 21:55:00.439684: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2022] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
            "2025-02-10 21:55:00.439733: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
            "Your kernel may have been built without NUMA support.\n",
            "2025-02-10 21:55:00.439772: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9711 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
            "INFO:absl:Fingerprint not found. Saved model loading will continue.\n",
            "INFO:absl:path_and_singleprint metric could not be logged. Saved model loading will continue.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total frames: 13\n",
            "processing frame 0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|\u001b[32m                                                                        \u001b[0m| 0/15 [00:00<?, ?it/s]\u001b[0m2025-02-10 21:55:03.868513: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8907\n",
            "100%|\u001b[32m███████████████████████████████████████████████████████████████\u001b[0m| 15/15 [01:02<00:00,  4.16s/it]\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "processing frame 1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|\u001b[32m███████████████████████████████████████████████████████████████\u001b[0m| 15/15 [00:13<00:00,  1.10it/s]\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "processing frame 2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|\u001b[32m███████████████████████████████████████████████████████████████\u001b[0m| 15/15 [00:13<00:00,  1.10it/s]\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "processing frame 3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|\u001b[32m███████████████████████████████████████████████████████████████\u001b[0m| 15/15 [00:13<00:00,  1.12it/s]\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "processing frame 4\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|\u001b[32m███████████████████████████████████████████████████████████████\u001b[0m| 15/15 [00:13<00:00,  1.11it/s]\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "processing frame 5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|\u001b[32m███████████████████████████████████████████████████████████████\u001b[0m| 15/15 [00:13<00:00,  1.11it/s]\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "processing frame 6\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|\u001b[32m███████████████████████████████████████████████████████████████\u001b[0m| 15/15 [00:13<00:00,  1.11it/s]\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "processing frame 7\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|\u001b[32m███████████████████████████████████████████████████████████████\u001b[0m| 15/15 [00:13<00:00,  1.11it/s]\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "processing frame 8\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|\u001b[32m███████████████████████████████████████████████████████████████\u001b[0m| 15/15 [00:13<00:00,  1.11it/s]\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "processing frame 9\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|\u001b[32m███████████████████████████████████████████████████████████████\u001b[0m| 15/15 [00:13<00:00,  1.11it/s]\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "processing frame 10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|\u001b[32m███████████████████████████████████████████████████████████████\u001b[0m| 15/15 [00:13<00:00,  1.11it/s]\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "processing frame 11\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|\u001b[32m███████████████████████████████████████████████████████████████\u001b[0m| 15/15 [00:13<00:00,  1.11it/s]\u001b[0m\n"
          ]
        },
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/tmp/tmp3235fmkm/2023_pathan_0000.jpg'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[13], line 50\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(files) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m     49\u001b[0m     new_filename \u001b[38;5;241m=\u001b[39m Path(processed_input_dir) \u001b[38;5;241m/\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mPath(end_filename)\u001b[38;5;241m.\u001b[39mstem\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_0000\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mPath(filename)\u001b[38;5;241m.\u001b[39msuffix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 50\u001b[0m     \u001b[43mshutil\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopyfile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_filename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnew_filename\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/miniconda3/envs/gputf/lib/python3.10/shutil.py:254\u001b[0m, in \u001b[0;36mcopyfile\u001b[0;34m(src, dst, follow_symlinks)\u001b[0m\n\u001b[1;32m    252\u001b[0m     os\u001b[38;5;241m.\u001b[39msymlink(os\u001b[38;5;241m.\u001b[39mreadlink(src), dst)\n\u001b[1;32m    253\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 254\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m fsrc:\n\u001b[1;32m    255\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    256\u001b[0m             \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(dst, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m fdst:\n\u001b[1;32m    257\u001b[0m                 \u001b[38;5;66;03m# macOS\u001b[39;00m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/tmp/tmp3235fmkm/2023_pathan_0000.jpg'"
          ]
        }
      ],
      "source": [
        "# Iterate through pairs of consecutive frames\n",
        "\n",
        "interpolator_model = interpolator.Interpolator(MODEL_PATH, None)\n",
        "print('Total frames:', len(files))\n",
        "create_empty_dir(OUTPUT_DIR)\n",
        "for i in range(len(files) - 1):\n",
        "    print('processing frame', i)\n",
        "    start_filename = files[i]\n",
        "    end_filename = files[i + 1]\n",
        "\n",
        "    if not equal_intervals:\n",
        "        start_time = string_to_timestamp(Path(start_filename).stem)\n",
        "        end_time = string_to_timestamp(Path(end_filename).stem)\n",
        "\n",
        "    # Calculate times_to_interpolate for the required number of intermediate frames\n",
        "    if equal_intervals:\n",
        "          num_frames_needed = MAX_INTERPOLATED_FRAMES\n",
        "    else:\n",
        "          # Calculate the time difference in hours\n",
        "          time_diff = (end_time - start_time).total_seconds()\n",
        "          num_frames_needed = round(time_diff / min_frame_duration) - 1\n",
        "          num_frames_needed = min(num_frames_needed, MAX_INTERPOLATED_FRAMES)\n",
        "    times_to_interpolate = math.ceil(math.log2(num_frames_needed+1))  # n_intermediate = 2^k - 1\n",
        "\n",
        "    frame_1 = start_filename\n",
        "    frame_2 = end_filename\n",
        "    output_frames = interpolate_frames(frame_1, frame_2, times_to_interpolate, interpolator_model)\n",
        "\n",
        "    create_empty_dir(temp_interpolated_frames_dir)\n",
        "    save_frames(output_frames, temp_interpolated_frames_dir)\n",
        "    interpolated_files = get_sorted_images(temp_interpolated_frames_dir)\n",
        "\n",
        "    if not equal_intervals:\n",
        "        timestamps = np.linspace(start_time.timestamp(), end_time.timestamp(), len(interpolated_files))\n",
        "        # find required frames from generated frames (can be extra)\n",
        "        chosen_timestamps = choose_evenly_spaced_timestamps(timestamps, num_frames_needed+2)\n",
        "        \n",
        "        for filename, timestamp in zip(interpolated_files, timestamps):\n",
        "            if timestamp not in chosen_timestamps:\n",
        "                continue\n",
        "            new_filename = Path(OUTPUT_DIR) / f\"{timestamp_to_string(timestamp)}{Path(filename).suffix}\"\n",
        "            shutil.copyfile(filename, new_filename)\n",
        "    else:\n",
        "        for interp_index, filename in enumerate(interpolated_files[:-1]):\n",
        "          new_filename = Path(OUTPUT_DIR) / f\"{Path(start_filename).stem}_{interp_index:04d}{Path(filename).suffix}\"\n",
        "          shutil.copyfile(filename, new_filename)\n",
        "          # include end frame in last iteration\n",
        "          if i == len(files) - 2:\n",
        "              new_filename = Path(processed_input_dir) / f\"{Path(end_filename).stem}_0000{Path(filename).suffix}\"\n",
        "              shutil.copyfile(end_filename, new_filename)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jC0lnT4o3k2l",
        "outputId": "34490167-2e78-4966-b600-2d3cdcce9be7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Video saved to: output_frames/shahrukh-khan.mp4\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# generate video from output directory\n",
        "output_path = str(OUTPUT_DIR) + '.mp4'\n",
        "fps = 24\n",
        "\n",
        "write_video_from_images(OUTPUT_DIR, output_path, fps)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mTnaWkjeEH3d"
      },
      "outputs": [],
      "source": [
        "# todo: try GAN using https://github.com/eladrich/pixel2style2pixel"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "gputf",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
