{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpolat between multple Frames to create a smooth animation time lapse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-09 12:03:10.273190: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-01-09 12:03:10.928952: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import tempfile\n",
    "import tensorflow as tf\n",
    "import mediapy\n",
    "import cv2\n",
    "from PIL import Image, ExifTags\n",
    "\n",
    "from natsort import natsorted\n",
    "import shutil\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "import subprocess\n",
    "import math\n",
    "import mediapy as media\n",
    "import sys\n",
    "from typing import Generator, Iterable, List, Optional\n",
    "\n",
    "\n",
    "from eval import interpolator, util\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the pretrained model\n",
    "import gdown\n",
    "os.makedirs('pretrained_models/film_net/Style/saved_model', exist_ok=True)\n",
    "\n",
    "if os.path.exists('pretrained_models/film_net/Style/saved_model/saved_model.pb'):\n",
    "    print('Model already downloaded')\n",
    "else:\n",
    "  folder_url = 'https://drive.google.com/drive/folders/1i9Go1YI2qiFWeT5QtywNFmYAA74bhXWj'\n",
    "  gdown.download_folder(folder_url, output='pretrained_models/film_net/Style/saved_model', quiet=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "MAX_DIM = 1080\n",
    "MAX_INTERPOLATED_FRAMES = 31  # 1 less than powers of 2\n",
    "MODEL_PATH = \"pretrained_models/film_net/Style/saved_model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if MAX_INTERPOLATED_FRAMES + 1 not in (2, 4, 8, 16, 32, 64, 128):\n",
    "    raise ValueError(\"MAX_INTERPOLATED_FRAMES + 1 must be a power of 2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir = 'input_frames/falake_window'\n",
    "output_dir = 'output_frames/lake_window'\n",
    "\n",
    "processed_input_dir = tempfile.mkdtemp()\n",
    "temp_interpolated_frames_dir = tempfile.mkdtemp()\n",
    "\n",
    "frame_interval = 3600 * 24 # gap between frames in seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Preprocess images\n",
    "# 2. for succesive pairs of images:\n",
    "# 3.     generate interpolated frames\n",
    "# 4.     add interpolated frames to the output directory\n",
    "# 5. generate video from output directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# create empty output directory\n",
    "def create_empty_dir(dir_name):\n",
    "  if os.path.exists(dir_name):\n",
    "    shutil.rmtree(dir_name)\n",
    "  os.makedirs(dir_name)\n",
    "\n",
    "\n",
    "def resize_and_save(input_path, output_path, size):\n",
    "  if input_path.endswith(('.png', '.jpg', '.jpeg', '.bmp', '.gif')):\n",
    "      img = Image.open(input_path)\n",
    "      img = img.resize(size, Image.Resampling.LANCZOS)\n",
    "      img.save(output_path)\n",
    "  else:\n",
    "      raise ValueError(f'Unsupported file format: {input_path}')\n",
    "\n",
    "\n",
    "# prepare input data\n",
    "def prepare_images(input_dir, processed_input_dir, size):\n",
    "  files = natsorted([f for f in os.listdir(input_dir) if f.endswith(('.png', '.jpg', '.jpeg', '.bmp', '.gif'))])\n",
    "  if len(files) < 0:\n",
    "    raise FileNotFoundError('no images found in input directory')\n",
    "  \n",
    "  for f in tqdm(files, desc='Preparing images'):\n",
    "    resize_and_save(os.path.join(input_dir, f), os.path.join(processed_input_dir, f), size)\n",
    "\n",
    "\n",
    "def get_new_size(image_path: str, max_dim: int = MAX_DIM) -> np.ndarray:\n",
    "    \"\"\"Resize the image so that the maximum dimension is `max_dim`.\"\"\"\n",
    "    image = cv2.imread(image_path)\n",
    "    h, w = image.shape[:2]\n",
    "    if h > w:\n",
    "        new_h = max_dim\n",
    "        new_w = int(w * new_h / h)\n",
    "    else:\n",
    "        new_w = max_dim\n",
    "        new_h = int(h * new_w / w)\n",
    "    return (new_w, new_h)\n",
    "\n",
    "\n",
    "def string_to_timestamp(datetime_str):\n",
    "    # Convert the datetime string to a datetime object\n",
    "    timestamp = datetime.strptime(datetime_str, \"%Y%m%d_%H%M%S\")\n",
    "    return timestamp\n",
    "\n",
    "\n",
    "def timestamp_to_string(timestamp):\n",
    "    # Convert the timestamp number to a datetime object\n",
    "    dt = datetime.fromtimestamp(timestamp)\n",
    "    # Format the datetime object to the desired string format\n",
    "    formatted_string = dt.strftime(\"%Y%m%d_%H%M%S\")\n",
    "    return formatted_string\n",
    "\n",
    "\n",
    "def choose_evenly_spaced_timestamps(timestamps, k):\n",
    "    # Ensure we have at least k timestamps\n",
    "    if k > len(timestamps):\n",
    "        raise ValueError(\"k cannot be greater than the number of timestamps\")\n",
    "\n",
    "    # Calculate the interval between timestamps\n",
    "    n = len(timestamps)\n",
    "    interval = (n - 1) / (k - 1)\n",
    "\n",
    "    # Select the timestamps\n",
    "    chosen_timestamps = []\n",
    "    for i in range(k):\n",
    "        index = round(i * interval)\n",
    "        chosen_timestamps.append(timestamps[index])\n",
    "\n",
    "    return chosen_timestamps\n",
    "\n",
    "\n",
    "def save_video(frames, out_path):\n",
    "    ffmpeg_path = util.get_ffmpeg_path()\n",
    "    mediapy.set_ffmpeg(ffmpeg_path)\n",
    "    mediapy.write_video(out_path, frames, fps=30)\n",
    "\n",
    "\n",
    "def save_frames(frames, output_dir, format='jpg'):\n",
    "    \"\"\"\n",
    "    Save interpolated frames to the specified output directory and return the output paths.\n",
    "    Args:\n",
    "        frames: List of image arrays\n",
    "        output_dir: Directory to save frames\n",
    "        format: Image format to save (jpg/png)\n",
    "    Returns:\n",
    "        list: List of file paths where the frames are saved.\n",
    "    \"\"\"\n",
    "    output_paths = []\n",
    "    for idx, frame in enumerate(frames):\n",
    "        output_path = os.path.join(output_dir, f'frame_{idx:06d}.{format}')\n",
    "        util.write_image(output_path, frame)\n",
    "        output_paths.append(output_path)\n",
    "    return output_paths\n",
    "\n",
    "\n",
    "def write_video_from_images(image_dir, output_path, fps):\n",
    "    image_files = sorted([f for f in os.listdir(image_dir) if f.endswith(('.png', '.jpg', '.jpeg'))])\n",
    "    \n",
    "    if not image_files:\n",
    "        print(\"No images found in the directory.\")\n",
    "        return\n",
    "    \n",
    "    # Read the first image to get the dimensions\n",
    "    first_image_path = os.path.join(image_dir, image_files[0])\n",
    "    first_frame = cv2.imread(first_image_path)\n",
    "    height, width, layers = first_frame.shape\n",
    "    \n",
    "    # Initialize the video writer\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # Specify the codec\n",
    "    video_writer = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
    "    \n",
    "    for image_file in image_files:\n",
    "        image_path = os.path.join(image_dir, image_file)\n",
    "        frame = cv2.imread(image_path)\n",
    "        if frame is None:\n",
    "            print(f\"Skipping {image_path}, cannot read image.\")\n",
    "            continue\n",
    "        video_writer.write(frame)\n",
    "    \n",
    "    video_writer.release()\n",
    "    print(f\"Video saved to: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def interpolate_frames(image_1, image_2, times_to_interpolate, interpolator):\n",
    "  input_frames = [str(image_1), str(image_2)]\n",
    "\n",
    "  frames = list(\n",
    "      util.interpolate_recursively_from_files(\n",
    "          input_frames, times_to_interpolate, interpolator))\n",
    "  return frames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preparing images:   0%|          | 0/24 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preparing images: 100%|██████████| 24/24 [00:00<00:00, 48.98it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preprocess images\n",
    "files = natsorted([f for f in os.listdir(input_dir) if f.endswith(('.png', '.jpg', '.jpeg', '.bmp', '.gif'))])\n",
    "new_size = get_new_size(os.path.join(input_dir, files[0]))\n",
    "create_empty_dir(output_dir)\n",
    "create_empty_dir(processed_input_dir)\n",
    "prepare_images(input_dir, processed_input_dir, new_size)\n",
    "files = natsorted([f for f in os.listdir(processed_input_dir) if f.endswith(('.png', '.jpg', '.jpeg'))])\n",
    "len(files)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filename: 20160512_234123.jpg, Datetime: 2016-05-12 23:41:23\n",
      "Filename: 20161214_220904.jpg, Datetime: 2016-12-14 22:09:04\n",
      "Filename: 20171005_180654.jpg, Datetime: 2017-10-05 18:06:54\n",
      "Filename: 20180814_184209.jpg, Datetime: 2018-08-14 18:42:09\n",
      "Filename: 20190202_191947.jpg, Datetime: 2019-02-02 19:19:47\n",
      "Filename: 20191122_084144.jpg, Datetime: 2019-11-22 08:41:44\n",
      "Filename: 20191201_134035.jpg, Datetime: 2019-12-01 13:40:35\n",
      "Filename: 20191226_214649.jpg, Datetime: 2019-12-26 21:46:49\n",
      "Filename: 20200521_091805.jpg, Datetime: 2020-05-21 09:18:05\n",
      "Filename: 20200803_091357.jpg, Datetime: 2020-08-03 09:13:57\n",
      "Filename: 20200819_092657.jpg, Datetime: 2020-08-19 09:26:57\n",
      "Filename: 20211230_090242.jpg, Datetime: 2021-12-30 09:02:42\n",
      "Filename: 20220105_095857.jpg, Datetime: 2022-01-05 09:58:57\n",
      "Filename: 20220130_204110.jpg, Datetime: 2022-01-30 20:41:10\n",
      "Filename: 20220203_231940.jpg, Datetime: 2022-02-03 23:19:40\n",
      "Filename: 20220531_124619.jpg, Datetime: 2022-05-31 12:46:19\n",
      "Filename: 20220713_113051.jpg, Datetime: 2022-07-13 11:30:51\n",
      "Filename: 20221122_190942.jpg, Datetime: 2022-11-22 19:09:42\n",
      "Filename: 20230303_081212.jpg, Datetime: 2023-03-03 08:12:12\n",
      "Filename: 20230423_173716.jpg, Datetime: 2023-04-23 17:37:16\n",
      "Filename: 20230519_094927.jpg, Datetime: 2023-05-19 09:49:27\n",
      "Filename: 20240428_174612.jpg, Datetime: 2024-04-28 17:46:12\n",
      "Filename: 20240522_202213.jpg, Datetime: 2024-05-22 20:22:13\n",
      "Filename: 20250106_075722.jpg, Datetime: 2025-01-06 07:57:22\n"
     ]
    }
   ],
   "source": [
    "for file in files:\n",
    "  timestamp = string_to_timestamp(file.split('.')[0])\n",
    "  print(f\"Filename: {file}, Datetime: {timestamp}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-09 12:03:55.140540: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-01-09 12:03:55.160544: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-01-09 12:03:55.160596: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-01-09 12:03:55.164131: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-01-09 12:03:55.164187: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-01-09 12:03:55.164202: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-01-09 12:03:55.297964: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-01-09 12:03:55.298041: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-01-09 12:03:55.298048: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1722] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2025-01-09 12:03:55.298069: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-01-09 12:03:55.298102: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9711 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total frames: 24\n",
      "processing frame 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[32m                                                                        \u001b[0m| 0/31 [00:00<?, ?it/s]\u001b[0m2025-01-09 12:03:57.168282: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [1,1080,711,3]\n",
      "\t [[{{node inputs}}]]\n",
      "2025-01-09 12:03:58.305775: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8902\n",
      "2025-01-09 12:04:02.410476: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "100%|\u001b[32m███████████████████████████████████████████████████████████████\u001b[0m| 31/31 [00:38<00:00,  1.25s/it]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing frame 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[32m███████████████████████████████████████████████████████████████\u001b[0m| 31/31 [00:22<00:00,  1.36it/s]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing frame 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[32m███████████████████████████████████████████████████████████████\u001b[0m| 31/31 [00:22<00:00,  1.37it/s]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing frame 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[32m███████████████████████████████████████████████████████████████\u001b[0m| 31/31 [00:22<00:00,  1.36it/s]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing frame 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[32m███████████████████████████████████████████████████████████████\u001b[0m| 31/31 [00:22<00:00,  1.36it/s]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing frame 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[32m███████████████████████████████████████████████████████████████\u001b[0m| 15/15 [00:10<00:00,  1.37it/s]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing frame 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[32m███████████████████████████████████████████████████████████████\u001b[0m| 31/31 [00:22<00:00,  1.37it/s]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing frame 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[32m███████████████████████████████████████████████████████████████\u001b[0m| 31/31 [00:22<00:00,  1.36it/s]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing frame 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[32m███████████████████████████████████████████████████████████████\u001b[0m| 31/31 [00:22<00:00,  1.36it/s]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing frame 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[32m███████████████████████████████████████████████████████████████\u001b[0m| 15/15 [00:11<00:00,  1.36it/s]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing frame 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[32m███████████████████████████████████████████████████████████████\u001b[0m| 31/31 [00:22<00:00,  1.36it/s]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing frame 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[32m█████████████████████████████████████████████████████████████████\u001b[0m| 7/7 [00:05<00:00,  1.37it/s]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing frame 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[32m███████████████████████████████████████████████████████████████\u001b[0m| 31/31 [00:22<00:00,  1.36it/s]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing frame 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[32m█████████████████████████████████████████████████████████████████\u001b[0m| 3/3 [00:02<00:00,  1.36it/s]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing frame 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[32m███████████████████████████████████████████████████████████████\u001b[0m| 31/31 [00:22<00:00,  1.36it/s]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing frame 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[32m███████████████████████████████████████████████████████████████\u001b[0m| 31/31 [00:22<00:00,  1.36it/s]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing frame 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[32m███████████████████████████████████████████████████████████████\u001b[0m| 31/31 [00:22<00:00,  1.36it/s]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing frame 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[32m███████████████████████████████████████████████████████████████\u001b[0m| 31/31 [00:22<00:00,  1.36it/s]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing frame 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[32m███████████████████████████████████████████████████████████████\u001b[0m| 31/31 [00:22<00:00,  1.36it/s]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing frame 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[32m███████████████████████████████████████████████████████████████\u001b[0m| 31/31 [00:22<00:00,  1.36it/s]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing frame 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[32m███████████████████████████████████████████████████████████████\u001b[0m| 31/31 [00:22<00:00,  1.36it/s]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing frame 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[32m███████████████████████████████████████████████████████████████\u001b[0m| 31/31 [00:22<00:00,  1.36it/s]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing frame 22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[32m███████████████████████████████████████████████████████████████\u001b[0m| 31/31 [00:22<00:00,  1.36it/s]\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Iterate through pairs of consecutive frames\n",
    "\n",
    "interpolator_model = interpolator.Interpolator(MODEL_PATH, None)\n",
    "print('Total frames:', len(files))\n",
    "for i in range(len(files) - 1):\n",
    "  print('processing frame', i)\n",
    "  start_filename = files[i]\n",
    "  end_filename = files[i + 1]\n",
    "\n",
    "  start_time = string_to_timestamp(start_filename.split('.')[0])\n",
    "  end_time = string_to_timestamp(end_filename.split('.')[0])\n",
    "\n",
    "  # Calculate the time difference in hours\n",
    "  time_diff = (end_time - start_time).total_seconds() / frame_interval\n",
    "\n",
    "  # Calculate times_to_interpolate for the required number of intermediate frames\n",
    "  num_frames_needed = round(time_diff) - 1\n",
    "  num_frames_needed = min(num_frames_needed, MAX_INTERPOLATED_FRAMES)\n",
    "  times_to_interpolate = math.ceil(math.log2(num_frames_needed+1))  # n_intermediate = 2^k - 1\n",
    "\n",
    "  frame_1 = os.path.join(processed_input_dir, start_filename)\n",
    "  frame_2 = os.path.join(processed_input_dir, end_filename)\n",
    "  output_frames = interpolate_frames(frame_1, frame_2, times_to_interpolate, interpolator_model)\n",
    "\n",
    "  create_empty_dir(temp_interpolated_frames_dir)\n",
    "  save_frames(output_frames, temp_interpolated_frames_dir)\n",
    "  interpolated_files = natsorted([f for f in os.listdir(temp_interpolated_frames_dir) if f.endswith(('.png', '.jpg', '.jpeg'))])\n",
    "\n",
    "  timestamps = np.linspace(start_time.timestamp(), end_time.timestamp(), len(interpolated_files))\n",
    "\n",
    "  len(timestamps), num_frames_needed, time_diff\n",
    "  # find required frames from generated frames (can be extra)\n",
    "  chosen_timestamps = choose_evenly_spaced_timestamps(timestamps, num_frames_needed+2)\n",
    "  for filename, timestamp in zip(interpolated_files, timestamps):\n",
    "    if timestamp not in chosen_timestamps:\n",
    "      continue\n",
    "    new_filename = f\"{timestamp_to_string(timestamp)}.{os.path.splitext(filename)[1]}\"\n",
    "    shutil.copyfile(os.path.join(temp_interpolated_frames_dir, filename), os.path.join(output_dir, new_filename))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# generate video from output directory\n",
    "output_path = str(output_dir) + '.mp4'\n",
    "fps = 24\n",
    "\n",
    "write_video_from_images(output_dir, output_path, fps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
