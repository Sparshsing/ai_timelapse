{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sparshsing/ai_timelapse/blob/main/time_lapse_Googe_Colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/Sparshsing/ai_timelapse.git"
      ],
      "metadata": {
        "id": "_kgDDtTe46tC",
        "outputId": "75df3490-739a-4c6e-eec3-6625b7870be1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'ai_timelapse'...\n",
            "remote: Enumerating objects: 82, done.\u001b[K\n",
            "remote: Counting objects: 100% (82/82), done.\u001b[K\n",
            "remote: Compressing objects: 100% (69/69), done.\u001b[K\n",
            "remote: Total 82 (delta 16), reused 79 (delta 13), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (82/82), 14.15 MiB | 33.47 MiB/s, done.\n",
            "Resolving deltas: 100% (16/16), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# change directory to ai_timelapse\n",
        "%cd ai_timelapse"
      ],
      "metadata": {
        "id": "kREPNgXA5tnY",
        "outputId": "3f7fb9af-c44d-4845-9b3c-b2bc4ef395a0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/ai_timelapse\n",
            "eval\t       README.md\t sample_data\t\t     time_lapse.ipynb\n",
            "fix_images.py  requirements.txt  simple_interpolation.ipynb\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.listdir()"
      ],
      "metadata": {
        "id": "lpfHWX8L5EL1",
        "outputId": "80e68aa5-9b55-4179-cb3a-a26868ee10e6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['sample_data',\n",
              " 'README.md',\n",
              " 'simple_interpolation.ipynb',\n",
              " 'fix_images.py',\n",
              " 'time_lapse.ipynb',\n",
              " 'eval',\n",
              " 'requirements.txt',\n",
              " '.gitignore',\n",
              " '.git']"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "Ksc3jxlD5guf",
        "outputId": "f04f7355-47e3-46fa-986d-a10d5516462f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: nvidia-smi: command not found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "61-YrGoj3k2i"
      },
      "source": [
        "## Generate smooth Time lapse from multiple sequencial images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "6iPjfJwa3k2j",
        "outputId": "89c9f7e8-9284-4c7e-b256-46844514365b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'mediapy'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-121c30aeeca3>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtempfile\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mmediapy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mPIL\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExifTags\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'mediapy'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import tempfile\n",
        "import tensorflow as tf\n",
        "import mediapy\n",
        "import cv2\n",
        "from PIL import Image, ExifTags\n",
        "\n",
        "from natsort import natsorted\n",
        "import shutil\n",
        "from tqdm import tqdm\n",
        "from datetime import datetime\n",
        "import subprocess\n",
        "import math\n",
        "import mediapy as media\n",
        "import sys\n",
        "from typing import Generator, Iterable, List, Optional\n",
        "\n",
        "\n",
        "from eval import interpolator, util\n",
        "import fix_images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "snJNybSe3k2j"
      },
      "source": [
        "## Config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sDVZ3dQR3k2k",
        "outputId": "018ba6ac-29f5-495c-d3f0-0a4d0812abad"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model already downloaded\n"
          ]
        }
      ],
      "source": [
        "# Download the pretrained model\n",
        "import gdown\n",
        "os.makedirs('pretrained_models/film_net/Style/saved_model', exist_ok=True)\n",
        "\n",
        "if os.path.exists('pretrained_models/film_net/Style/saved_model/saved_model.pb'):\n",
        "    print('Model already downloaded')\n",
        "else:\n",
        "  folder_url = 'https://drive.google.com/drive/folders/1i9Go1YI2qiFWeT5QtywNFmYAA74bhXWj'\n",
        "  gdown.download_folder(folder_url, output='pretrained_models/film_net/Style/saved_model', quiet=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nwB5mYvR3k2k"
      },
      "outputs": [],
      "source": [
        "\n",
        "MAX_DIM = 1080\n",
        "# set no of interpolated frames between images\n",
        "MAX_INTERPOLATED_FRAMES = 63  # 1 less than powers of 2\n",
        "MODEL_PATH = \"pretrained_models/film_net/Style/saved_model\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uVxhyExg3k2k"
      },
      "outputs": [],
      "source": [
        "if MAX_INTERPOLATED_FRAMES + 1 not in (2, 4, 8, 16, 32, 64, 128):\n",
        "    raise ValueError(\"MAX_INTERPOLATED_FRAMES + 1 must be a power of 2\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vdgoCPVo3k2k"
      },
      "outputs": [],
      "source": [
        "input_dir = 'input_frames/shahrukh-khan'\n",
        "output_dir = 'output_frames/shahrukh-khan'\n",
        "preprocess_faces = True\n",
        "equal_intervals = True  # whether to use equal no of frames between images or decide based on date\n",
        "\n",
        "# applicable when equal_intervals is False\n",
        "# desired gap between frames in seconds (difference between dates of frames)\n",
        "# eg. set 3600 to generate 1 frame for every 1 hr gap in input images\n",
        "min_frame_duration = 3600 * 24\n",
        "\n",
        "processed_input_dir = tempfile.mkdtemp()\n",
        "temp_interpolated_frames_dir = tempfile.mkdtemp()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wgpvI8G83k2k"
      },
      "source": [
        "## Plan"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dVhGZ5ct3k2k"
      },
      "outputs": [],
      "source": [
        "# 1. Preprocess images\n",
        "# 2. for succesive pairs of images:\n",
        "# 3.     generate interpolated frames\n",
        "# 4.     add interpolated frames to the output directory\n",
        "# 5. generate video from output directory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3WIJ6zNr3k2k"
      },
      "source": [
        "## Utility Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "peMfh7q33k2k"
      },
      "outputs": [],
      "source": [
        "\n",
        "# create empty output directory\n",
        "def create_empty_dir(dir_name):\n",
        "  if os.path.exists(dir_name):\n",
        "    shutil.rmtree(dir_name)\n",
        "  os.makedirs(dir_name)\n",
        "\n",
        "\n",
        "def resize_and_save(input_path, output_path, size):\n",
        "  if input_path.endswith(('.png', '.jpg', '.jpeg', '.bmp')):\n",
        "      img = Image.open(input_path)\n",
        "      img = img.resize(size, Image.Resampling.LANCZOS)\n",
        "      img.save(output_path)\n",
        "  else:\n",
        "      raise ValueError(f'Unsupported file format: {input_path}')\n",
        "\n",
        "\n",
        "# prepare input data\n",
        "def prepare_images(input_dir, processed_input_dir, preprocess_faces, size):\n",
        "  files = natsorted([f for f in os.listdir(input_dir) if f.endswith(('.png', '.jpg', '.jpeg', '.bmp'))])\n",
        "  if len(files) < 0:\n",
        "    raise FileNotFoundError('no images found in input directory')\n",
        "\n",
        "  for f in tqdm(files, desc='Preparing images'):\n",
        "    if preprocess_faces:\n",
        "       fix_images.process_face_image(\n",
        "            os.path.join(input_dir, f),\n",
        "            os.path.join(processed_input_dir, f),\n",
        "            background_color=(255, 255, 255),  # White background\n",
        "            save_bbox_preview=False\n",
        "            )\n",
        "    else:\n",
        "        resize_and_save(os.path.join(input_dir, f), os.path.join(processed_input_dir, f), size)\n",
        "\n",
        "\n",
        "def get_new_size(image_path: str, max_dim: int = MAX_DIM) -> np.ndarray:\n",
        "    \"\"\"Resize the image so that the maximum dimension is `max_dim`.\"\"\"\n",
        "    image = cv2.imread(image_path)\n",
        "    h, w = image.shape[:2]\n",
        "    if h > w:\n",
        "        new_h = max_dim\n",
        "        new_w = int(w * new_h / h)\n",
        "    else:\n",
        "        new_w = max_dim\n",
        "        new_h = int(h * new_w / w)\n",
        "    return (new_w, new_h)\n",
        "\n",
        "\n",
        "def string_to_timestamp(datetime_str):\n",
        "    # Convert the datetime string to a datetime object\n",
        "    timestamp = datetime.strptime(datetime_str, \"%Y%m%d_%H%M%S\")\n",
        "    return timestamp\n",
        "\n",
        "\n",
        "def timestamp_to_string(timestamp):\n",
        "    # Convert the timestamp number to a datetime object\n",
        "    dt = datetime.fromtimestamp(timestamp)\n",
        "    # Format the datetime object to the desired string format\n",
        "    formatted_string = dt.strftime(\"%Y%m%d_%H%M%S\")\n",
        "    return formatted_string\n",
        "\n",
        "\n",
        "def choose_evenly_spaced_timestamps(timestamps, k):\n",
        "    # Ensure we have at least k timestamps\n",
        "    if k > len(timestamps):\n",
        "        raise ValueError(\"k cannot be greater than the number of timestamps\")\n",
        "\n",
        "    # Calculate the interval between timestamps\n",
        "    n = len(timestamps)\n",
        "    interval = (n - 1) / (k - 1)\n",
        "\n",
        "    # Select the timestamps\n",
        "    chosen_timestamps = []\n",
        "    for i in range(k):\n",
        "        index = round(i * interval)\n",
        "        chosen_timestamps.append(timestamps[index])\n",
        "\n",
        "    return chosen_timestamps\n",
        "\n",
        "\n",
        "def save_video(frames, out_path):\n",
        "    ffmpeg_path = util.get_ffmpeg_path()\n",
        "    mediapy.set_ffmpeg(ffmpeg_path)\n",
        "    mediapy.write_video(out_path, frames, fps=30)\n",
        "\n",
        "\n",
        "def save_frames(frames, output_dir, format='jpg'):\n",
        "    \"\"\"\n",
        "    Save interpolated frames to the specified output directory and return the output paths.\n",
        "    Args:\n",
        "        frames: List of image arrays\n",
        "        output_dir: Directory to save frames\n",
        "        format: Image format to save (jpg/png)\n",
        "    Returns:\n",
        "        list: List of file paths where the frames are saved.\n",
        "    \"\"\"\n",
        "    output_paths = []\n",
        "    for idx, frame in enumerate(frames):\n",
        "        output_path = os.path.join(output_dir, f'frame_{idx:06d}.{format}')\n",
        "        util.write_image(output_path, frame)\n",
        "        output_paths.append(output_path)\n",
        "    return output_paths\n",
        "\n",
        "\n",
        "def write_video_from_images(image_dir, output_path, fps):\n",
        "    image_files = natsorted([f for f in os.listdir(image_dir) if f.endswith(('.png', '.jpg', '.jpeg', '.bmp'))])\n",
        "\n",
        "    if not image_files:\n",
        "        print(\"No images found in the directory.\")\n",
        "        return\n",
        "\n",
        "    # Read the first image to get the dimensions\n",
        "    first_image_path = os.path.join(image_dir, image_files[0])\n",
        "    first_frame = cv2.imread(first_image_path)\n",
        "    height, width, layers = first_frame.shape\n",
        "\n",
        "    # Initialize the video writer\n",
        "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # Specify the codec\n",
        "    video_writer = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
        "\n",
        "    for image_file in image_files:\n",
        "        image_path = os.path.join(image_dir, image_file)\n",
        "        frame = cv2.imread(image_path)\n",
        "        if frame is None:\n",
        "            print(f\"Skipping {image_path}, cannot read image.\")\n",
        "            continue\n",
        "        video_writer.write(frame)\n",
        "\n",
        "    video_writer.release()\n",
        "    print(f\"Video saved to: {output_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3xUYjgHd3k2k"
      },
      "outputs": [],
      "source": [
        "\n",
        "def interpolate_frames(image_1, image_2, times_to_interpolate, interpolator):\n",
        "  input_frames = [str(image_1), str(image_2)]\n",
        "\n",
        "  frames = list(\n",
        "      util.interpolate_recursively_from_files(\n",
        "          input_frames, times_to_interpolate, interpolator))\n",
        "  return frames"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qNI760nM3k2l"
      },
      "source": [
        "## Main"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gzC7E2oK3k2l",
        "outputId": "ba6473ce-4437-43be-d91d-43385f4c9559"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Preparing images:   0%|          | 0/13 [00:00<?, ?it/s]INFO:fix_images:Processing image: input_frames/shahrukh-khan/1992_deewana.jpg\n",
            "INFO:fix_images:Image loaded successfully\n",
            "libEGL warning: MESA-LOADER: failed to open swrast: /usr/lib/dri/swrast_dri.so: cannot open shared object file: No such file or directory (search paths /usr/lib/x86_64-linux-gnu/dri:\\$${ORIGIN}/dri:/usr/lib/dri, suffix _dri)\n",
            "\n",
            "libEGL warning: MESA-LOADER: failed to open swrast: /usr/lib/dri/swrast_dri.so: cannot open shared object file: No such file or directory (search paths /usr/lib/x86_64-linux-gnu/dri:\\$${ORIGIN}/dri:/usr/lib/dri, suffix _dri)\n",
            "\n",
            "W0000 00:00:1736492930.935134   95361 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
            "INFO:fix_images:Face detected successfully\n",
            "INFO:fix_images:Image cropped and centered\n",
            "INFO:fix_images:Image resized\n",
            "INFO:fix_images:Background removed\n",
            "INFO:fix_images:Processed image saved to: /tmp/tmp9wwieqfj/1992_deewana.jpg\n",
            "Preparing images:   8%|▊         | 1/13 [00:00<00:09,  1.30it/s]INFO:fix_images:Processing image: input_frames/shahrukh-khan/1993_baazigar.jpg\n",
            "INFO:fix_images:Image loaded successfully\n",
            "libEGL warning: MESA-LOADER: failed to open swrast: /usr/lib/dri/swrast_dri.so: cannot open shared object file: No such file or directory (search paths /usr/lib/x86_64-linux-gnu/dri:\\$${ORIGIN}/dri:/usr/lib/dri, suffix _dri)\n",
            "\n",
            "libEGL warning: MESA-LOADER: failed to open swrast: /usr/lib/dri/swrast_dri.so: cannot open shared object file: No such file or directory (search paths /usr/lib/x86_64-linux-gnu/dri:\\$${ORIGIN}/dri:/usr/lib/dri, suffix _dri)\n",
            "\n",
            "W0000 00:00:1736492931.695862   95378 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
            "INFO:fix_images:Face detected successfully\n",
            "INFO:fix_images:Image cropped and centered\n",
            "INFO:fix_images:Image resized\n",
            "INFO:fix_images:Background removed\n",
            "INFO:fix_images:Processed image saved to: /tmp/tmp9wwieqfj/1993_baazigar.jpg\n",
            "Preparing images:  15%|█▌        | 2/13 [00:01<00:08,  1.36it/s]INFO:fix_images:Processing image: input_frames/shahrukh-khan/1995_ddlj.jpg\n",
            "INFO:fix_images:Image loaded successfully\n",
            "libEGL warning: MESA-LOADER: failed to open swrast: /usr/lib/dri/swrast_dri.so: cannot open shared object file: No such file or directory (search paths /usr/lib/x86_64-linux-gnu/dri:\\$${ORIGIN}/dri:/usr/lib/dri, suffix _dri)\n",
            "\n",
            "libEGL warning: MESA-LOADER: failed to open swrast: /usr/lib/dri/swrast_dri.so: cannot open shared object file: No such file or directory (search paths /usr/lib/x86_64-linux-gnu/dri:\\$${ORIGIN}/dri:/usr/lib/dri, suffix _dri)\n",
            "\n",
            "W0000 00:00:1736492932.404799   95398 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
            "INFO:fix_images:Face detected successfully\n",
            "INFO:fix_images:Image cropped and centered\n",
            "INFO:fix_images:Image resized\n",
            "INFO:fix_images:Background removed\n",
            "INFO:fix_images:Processed image saved to: /tmp/tmp9wwieqfj/1995_ddlj.jpg\n",
            "Preparing images:  23%|██▎       | 3/13 [00:02<00:07,  1.36it/s]INFO:fix_images:Processing image: input_frames/shahrukh-khan/1998_kuch_kuch_hota_hai.jpg\n",
            "INFO:fix_images:Image loaded successfully\n",
            "libEGL warning: MESA-LOADER: failed to open swrast: /usr/lib/dri/swrast_dri.so: cannot open shared object file: No such file or directory (search paths /usr/lib/x86_64-linux-gnu/dri:\\$${ORIGIN}/dri:/usr/lib/dri, suffix _dri)\n",
            "\n",
            "libEGL warning: MESA-LOADER: failed to open swrast: /usr/lib/dri/swrast_dri.so: cannot open shared object file: No such file or directory (search paths /usr/lib/x86_64-linux-gnu/dri:\\$${ORIGIN}/dri:/usr/lib/dri, suffix _dri)\n",
            "\n",
            "W0000 00:00:1736492933.143784   95413 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
            "INFO:fix_images:Face detected successfully\n",
            "INFO:fix_images:Image cropped and centered\n",
            "INFO:fix_images:Image resized\n",
            "INFO:fix_images:Background removed\n",
            "INFO:fix_images:Processed image saved to: /tmp/tmp9wwieqfj/1998_kuch_kuch_hota_hai.jpg\n",
            "Preparing images:  31%|███       | 4/13 [00:02<00:06,  1.36it/s]INFO:fix_images:Processing image: input_frames/shahrukh-khan/2001_kbkg.jpg\n",
            "INFO:fix_images:Image loaded successfully\n",
            "libEGL warning: MESA-LOADER: failed to open swrast: /usr/lib/dri/swrast_dri.so: cannot open shared object file: No such file or directory (search paths /usr/lib/x86_64-linux-gnu/dri:\\$${ORIGIN}/dri:/usr/lib/dri, suffix _dri)\n",
            "\n",
            "libEGL warning: MESA-LOADER: failed to open swrast: /usr/lib/dri/swrast_dri.so: cannot open shared object file: No such file or directory (search paths /usr/lib/x86_64-linux-gnu/dri:\\$${ORIGIN}/dri:/usr/lib/dri, suffix _dri)\n",
            "\n",
            "W0000 00:00:1736492933.873388   95430 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
            "INFO:fix_images:Face detected successfully\n",
            "INFO:fix_images:Image cropped and centered\n",
            "INFO:fix_images:Image resized\n",
            "INFO:fix_images:Background removed\n",
            "INFO:fix_images:Processed image saved to: /tmp/tmp9wwieqfj/2001_kbkg.jpg\n",
            "Preparing images:  38%|███▊      | 5/13 [00:03<00:05,  1.39it/s]INFO:fix_images:Processing image: input_frames/shahrukh-khan/2003_kal_ho_na_ho.jpeg\n",
            "INFO:fix_images:Image loaded successfully\n",
            "libEGL warning: MESA-LOADER: failed to open swrast: /usr/lib/dri/swrast_dri.so: cannot open shared object file: No such file or directory (search paths /usr/lib/x86_64-linux-gnu/dri:\\$${ORIGIN}/dri:/usr/lib/dri, suffix _dri)\n",
            "\n",
            "libEGL warning: MESA-LOADER: failed to open swrast: /usr/lib/dri/swrast_dri.so: cannot open shared object file: No such file or directory (search paths /usr/lib/x86_64-linux-gnu/dri:\\$${ORIGIN}/dri:/usr/lib/dri, suffix _dri)\n",
            "\n",
            "W0000 00:00:1736492934.572536   95446 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
            "INFO:fix_images:Face detected successfully\n",
            "INFO:fix_images:Image cropped and centered\n",
            "INFO:fix_images:Image resized\n",
            "INFO:fix_images:Background removed\n",
            "INFO:fix_images:Processed image saved to: /tmp/tmp9wwieqfj/2003_kal_ho_na_ho.jpeg\n",
            "Preparing images:  46%|████▌     | 6/13 [00:04<00:04,  1.40it/s]INFO:fix_images:Processing image: input_frames/shahrukh-khan/2006_kabh_alvida.jpg\n",
            "INFO:fix_images:Image loaded successfully\n",
            "libEGL warning: MESA-LOADER: failed to open swrast: /usr/lib/dri/swrast_dri.so: cannot open shared object file: No such file or directory (search paths /usr/lib/x86_64-linux-gnu/dri:\\$${ORIGIN}/dri:/usr/lib/dri, suffix _dri)\n",
            "\n",
            "libEGL warning: MESA-LOADER: failed to open swrast: /usr/lib/dri/swrast_dri.so: cannot open shared object file: No such file or directory (search paths /usr/lib/x86_64-linux-gnu/dri:\\$${ORIGIN}/dri:/usr/lib/dri, suffix _dri)\n",
            "\n",
            "W0000 00:00:1736492935.268152   95462 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
            "INFO:fix_images:Face detected successfully\n",
            "INFO:fix_images:Image cropped and centered\n",
            "INFO:fix_images:Image resized\n",
            "INFO:fix_images:Background removed\n",
            "INFO:fix_images:Processed image saved to: /tmp/tmp9wwieqfj/2006_kabh_alvida.jpg\n",
            "Preparing images:  54%|█████▍    | 7/13 [00:05<00:04,  1.40it/s]INFO:fix_images:Processing image: input_frames/shahrukh-khan/2009_billu.jpg\n",
            "INFO:fix_images:Image loaded successfully\n",
            "libEGL warning: MESA-LOADER: failed to open swrast: /usr/lib/dri/swrast_dri.so: cannot open shared object file: No such file or directory (search paths /usr/lib/x86_64-linux-gnu/dri:\\$${ORIGIN}/dri:/usr/lib/dri, suffix _dri)\n",
            "\n",
            "libEGL warning: MESA-LOADER: failed to open swrast: /usr/lib/dri/swrast_dri.so: cannot open shared object file: No such file or directory (search paths /usr/lib/x86_64-linux-gnu/dri:\\$${ORIGIN}/dri:/usr/lib/dri, suffix _dri)\n",
            "\n",
            "W0000 00:00:1736492935.992149   95478 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
            "INFO:fix_images:Face detected successfully\n",
            "INFO:fix_images:Image cropped and centered\n",
            "INFO:fix_images:Image resized\n",
            "INFO:fix_images:Background removed\n",
            "INFO:fix_images:Processed image saved to: /tmp/tmp9wwieqfj/2009_billu.jpg\n",
            "Preparing images:  62%|██████▏   | 8/13 [00:05<00:03,  1.39it/s]INFO:fix_images:Processing image: input_frames/shahrukh-khan/2011_don.jpg\n",
            "INFO:fix_images:Image loaded successfully\n",
            "libEGL warning: MESA-LOADER: failed to open swrast: /usr/lib/dri/swrast_dri.so: cannot open shared object file: No such file or directory (search paths /usr/lib/x86_64-linux-gnu/dri:\\$${ORIGIN}/dri:/usr/lib/dri, suffix _dri)\n",
            "\n",
            "libEGL warning: MESA-LOADER: failed to open swrast: /usr/lib/dri/swrast_dri.so: cannot open shared object file: No such file or directory (search paths /usr/lib/x86_64-linux-gnu/dri:\\$${ORIGIN}/dri:/usr/lib/dri, suffix _dri)\n",
            "\n",
            "W0000 00:00:1736492936.714490   95494 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
            "INFO:fix_images:Face detected successfully\n",
            "INFO:fix_images:Image cropped and centered\n",
            "INFO:fix_images:Image resized\n",
            "INFO:fix_images:Background removed\n",
            "INFO:fix_images:Processed image saved to: /tmp/tmp9wwieqfj/2011_don.jpg\n",
            "Preparing images:  69%|██████▉   | 9/13 [00:06<00:02,  1.38it/s]INFO:fix_images:Processing image: input_frames/shahrukh-khan/2014_hny.jpg\n",
            "INFO:fix_images:Image loaded successfully\n",
            "libEGL warning: MESA-LOADER: failed to open swrast: /usr/lib/dri/swrast_dri.so: cannot open shared object file: No such file or directory (search paths /usr/lib/x86_64-linux-gnu/dri:\\$${ORIGIN}/dri:/usr/lib/dri, suffix _dri)\n",
            "\n",
            "libEGL warning: MESA-LOADER: failed to open swrast: /usr/lib/dri/swrast_dri.so: cannot open shared object file: No such file or directory (search paths /usr/lib/x86_64-linux-gnu/dri:\\$${ORIGIN}/dri:/usr/lib/dri, suffix _dri)\n",
            "\n",
            "W0000 00:00:1736492937.447572   95510 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
            "INFO:fix_images:Face detected successfully\n",
            "INFO:fix_images:Image cropped and centered\n",
            "INFO:fix_images:Image resized\n",
            "INFO:fix_images:Background removed\n",
            "INFO:fix_images:Processed image saved to: /tmp/tmp9wwieqfj/2014_hny.jpg\n",
            "Preparing images:  77%|███████▋  | 10/13 [00:07<00:02,  1.39it/s]INFO:fix_images:Processing image: input_frames/shahrukh-khan/2017_raees.jpg\n",
            "INFO:fix_images:Image loaded successfully\n",
            "libEGL warning: MESA-LOADER: failed to open swrast: /usr/lib/dri/swrast_dri.so: cannot open shared object file: No such file or directory (search paths /usr/lib/x86_64-linux-gnu/dri:\\$${ORIGIN}/dri:/usr/lib/dri, suffix _dri)\n",
            "\n",
            "libEGL warning: MESA-LOADER: failed to open swrast: /usr/lib/dri/swrast_dri.so: cannot open shared object file: No such file or directory (search paths /usr/lib/x86_64-linux-gnu/dri:\\$${ORIGIN}/dri:/usr/lib/dri, suffix _dri)\n",
            "\n",
            "W0000 00:00:1736492938.166610   95526 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
            "INFO:fix_images:Face detected successfully\n",
            "INFO:fix_images:Image cropped and centered\n",
            "INFO:fix_images:Image resized\n",
            "INFO:fix_images:Background removed\n",
            "INFO:fix_images:Processed image saved to: /tmp/tmp9wwieqfj/2017_raees.jpg\n",
            "Preparing images:  85%|████████▍ | 11/13 [00:07<00:01,  1.39it/s]INFO:fix_images:Processing image: input_frames/shahrukh-khan/2019_media.jpg\n",
            "INFO:fix_images:Image loaded successfully\n",
            "libEGL warning: MESA-LOADER: failed to open swrast: /usr/lib/dri/swrast_dri.so: cannot open shared object file: No such file or directory (search paths /usr/lib/x86_64-linux-gnu/dri:\\$${ORIGIN}/dri:/usr/lib/dri, suffix _dri)\n",
            "\n",
            "libEGL warning: MESA-LOADER: failed to open swrast: /usr/lib/dri/swrast_dri.so: cannot open shared object file: No such file or directory (search paths /usr/lib/x86_64-linux-gnu/dri:\\$${ORIGIN}/dri:/usr/lib/dri, suffix _dri)\n",
            "\n",
            "W0000 00:00:1736492938.879571   95542 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
            "INFO:fix_images:Face detected successfully\n",
            "INFO:fix_images:Image cropped and centered\n",
            "INFO:fix_images:Image resized\n",
            "INFO:fix_images:Background removed\n",
            "INFO:fix_images:Processed image saved to: /tmp/tmp9wwieqfj/2019_media.jpg\n",
            "Preparing images:  92%|█████████▏| 12/13 [00:08<00:00,  1.38it/s]INFO:fix_images:Processing image: input_frames/shahrukh-khan/2023_pathan.jpg\n",
            "INFO:fix_images:Image loaded successfully\n",
            "libEGL warning: MESA-LOADER: failed to open swrast: /usr/lib/dri/swrast_dri.so: cannot open shared object file: No such file or directory (search paths /usr/lib/x86_64-linux-gnu/dri:\\$${ORIGIN}/dri:/usr/lib/dri, suffix _dri)\n",
            "\n",
            "libEGL warning: MESA-LOADER: failed to open swrast: /usr/lib/dri/swrast_dri.so: cannot open shared object file: No such file or directory (search paths /usr/lib/x86_64-linux-gnu/dri:\\$${ORIGIN}/dri:/usr/lib/dri, suffix _dri)\n",
            "\n",
            "W0000 00:00:1736492939.619268   95557 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
            "INFO:fix_images:Face detected successfully\n",
            "INFO:fix_images:Image cropped and centered\n",
            "INFO:fix_images:Image resized\n",
            "INFO:fix_images:Background removed\n",
            "INFO:fix_images:Processed image saved to: /tmp/tmp9wwieqfj/2023_pathan.jpg\n",
            "Preparing images: 100%|██████████| 13/13 [00:09<00:00,  1.38it/s]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "13"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Preprocess images\n",
        "files = natsorted([f for f in os.listdir(input_dir) if f.endswith(('.png', '.jpg', '.jpeg', '.bmp'))])\n",
        "new_size = get_new_size(os.path.join(input_dir, files[0]))\n",
        "create_empty_dir(processed_input_dir)\n",
        "prepare_images(input_dir, processed_input_dir, preprocess_faces, new_size)\n",
        "files = natsorted([f for f in os.listdir(processed_input_dir) if f.endswith(('.png', '.jpg', '.jpeg', '.bmp'))])\n",
        "len(files)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u5gnR-pS3k2l",
        "outputId": "dda41fc7-4eee-4b53-9c1d-efb97958a77b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Filename: 1992_deewana.jpg\n",
            "Filename: 1993_baazigar.jpg\n",
            "Filename: 1995_ddlj.jpg\n",
            "Filename: 1998_kuch_kuch_hota_hai.jpg\n",
            "Filename: 2001_kbkg.jpg\n",
            "Filename: 2003_kal_ho_na_ho.jpeg\n",
            "Filename: 2006_kabh_alvida.jpg\n",
            "Filename: 2009_billu.jpg\n",
            "Filename: 2011_don.jpg\n",
            "Filename: 2014_hny.jpg\n",
            "Filename: 2017_raees.jpg\n",
            "Filename: 2019_media.jpg\n",
            "Filename: 2023_pathan.jpg\n"
          ]
        }
      ],
      "source": [
        "if not equal_intervals:\n",
        "    for file in files:\n",
        "      timestamp = string_to_timestamp(file.split('.')[0])\n",
        "      print(f\"Filename: {file}, Datetime: {timestamp}\")\n",
        "else:\n",
        "   for file in files:\n",
        "      print(f\"Filename: {file}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "344GgQzX3k2l",
        "outputId": "e49f0603-31f8-4bd6-cab9-43d108603aff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total frames: 13\n",
            "processing frame 0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-01-10 14:24:05.836596: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [1,1000,1000,3]\n",
            "\t [[{{node inputs}}]]\n",
            "100%|\u001b[32m███████████████████████████████████████████████████████████████\u001b[0m| 63/63 [01:01<00:00,  1.02it/s]\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "processing frame 1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|\u001b[32m███████████████████████████████████████████████████████████████\u001b[0m| 63/63 [01:00<00:00,  1.05it/s]\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "processing frame 2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|\u001b[32m███████████████████████████████████████████████████████████████\u001b[0m| 63/63 [01:00<00:00,  1.05it/s]\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "processing frame 3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|\u001b[32m███████████████████████████████████████████████████████████████\u001b[0m| 63/63 [01:00<00:00,  1.05it/s]\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "processing frame 4\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|\u001b[32m███████████████████████████████████████████████████████████████\u001b[0m| 63/63 [01:00<00:00,  1.04it/s]\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "processing frame 5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|\u001b[32m███████████████████████████████████████████████████████████████\u001b[0m| 63/63 [01:00<00:00,  1.04it/s]\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "processing frame 6\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|\u001b[32m███████████████████████████████████████████████████████████████\u001b[0m| 63/63 [01:00<00:00,  1.05it/s]\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "processing frame 7\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|\u001b[32m███████████████████████████████████████████████████████████████\u001b[0m| 63/63 [01:00<00:00,  1.04it/s]\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "processing frame 8\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|\u001b[32m███████████████████████████████████████████████████████████████\u001b[0m| 63/63 [01:00<00:00,  1.04it/s]\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "processing frame 9\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|\u001b[32m███████████████████████████████████████████████████████████████\u001b[0m| 63/63 [01:00<00:00,  1.05it/s]\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "processing frame 10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|\u001b[32m███████████████████████████████████████████████████████████████\u001b[0m| 63/63 [01:00<00:00,  1.05it/s]\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "processing frame 11\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|\u001b[32m███████████████████████████████████████████████████████████████\u001b[0m| 63/63 [01:00<00:00,  1.05it/s]\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "# Iterate through pairs of consecutive frames\n",
        "\n",
        "interpolator_model = interpolator.Interpolator(MODEL_PATH, None)\n",
        "print('Total frames:', len(files))\n",
        "create_empty_dir(output_dir)\n",
        "for i in range(len(files) - 1):\n",
        "    print('processing frame', i)\n",
        "    start_filename = files[i]\n",
        "    end_filename = files[i + 1]\n",
        "\n",
        "    if not equal_intervals:\n",
        "        start_time = string_to_timestamp(start_filename.split('.')[0])\n",
        "        end_time = string_to_timestamp(end_filename.split('.')[0])\n",
        "\n",
        "    # Calculate times_to_interpolate for the required number of intermediate frames\n",
        "    if equal_intervals:\n",
        "          num_frames_needed = MAX_INTERPOLATED_FRAMES\n",
        "    else:\n",
        "          # Calculate the time difference in hours\n",
        "          time_diff = (end_time - start_time).total_seconds()\n",
        "          num_frames_needed = round(time_diff / min_frame_duration) - 1\n",
        "          num_frames_needed = min(num_frames_needed, MAX_INTERPOLATED_FRAMES)\n",
        "    times_to_interpolate = math.ceil(math.log2(num_frames_needed+1))  # n_intermediate = 2^k - 1\n",
        "\n",
        "    frame_1 = os.path.join(processed_input_dir, start_filename)\n",
        "    frame_2 = os.path.join(processed_input_dir, end_filename)\n",
        "    output_frames = interpolate_frames(frame_1, frame_2, times_to_interpolate, interpolator_model)\n",
        "\n",
        "    create_empty_dir(temp_interpolated_frames_dir)\n",
        "    save_frames(output_frames, temp_interpolated_frames_dir)\n",
        "    interpolated_files = natsorted([f for f in os.listdir(temp_interpolated_frames_dir) if f.endswith(('.png', '.jpg', '.jpeg', '.bmp'))])\n",
        "\n",
        "    if not equal_intervals:\n",
        "        timestamps = np.linspace(start_time.timestamp(), end_time.timestamp(), len(interpolated_files))\n",
        "        # find required frames from generated frames (can be extra)\n",
        "        chosen_timestamps = choose_evenly_spaced_timestamps(timestamps, num_frames_needed+2)\n",
        "\n",
        "        for filename, timestamp in zip(interpolated_files, timestamps):\n",
        "            if timestamp not in chosen_timestamps:\n",
        "                continue\n",
        "            new_filename = f\"{timestamp_to_string(timestamp)}{os.path.splitext(filename)[1]}\"\n",
        "            shutil.copyfile(os.path.join(temp_interpolated_frames_dir, filename), os.path.join(output_dir, new_filename))\n",
        "    else:\n",
        "        for interp_index, filename in enumerate(interpolated_files[:-1]):\n",
        "          new_filename = f\"{start_filename.split('.')[0]}_{interp_index}{os.path.splitext(filename)[1]}\"\n",
        "          shutil.copyfile(os.path.join(temp_interpolated_frames_dir, filename), os.path.join(output_dir, new_filename))\n",
        "          # include end frame in last iteration\n",
        "          if i == len(files) - 2:\n",
        "              new_filename = f\"{end_filename.split('.')[0]}_0{os.path.splitext(filename)[1]}\"\n",
        "              shutil.copyfile(os.path.join(processed_input_dir, end_filename), os.path.join(output_dir, new_filename))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jC0lnT4o3k2l",
        "outputId": "902aaffd-173d-4c2b-acb6-a66f8e00cf26"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Video saved to: output_frames/shahrukh-khan.mp4\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# generate video from output directory\n",
        "output_path = str(output_dir) + '.mp4'\n",
        "fps = 24\n",
        "\n",
        "write_video_from_images(output_dir, output_path, fps)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "tf",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}